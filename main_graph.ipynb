{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0f378072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6da3ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_f_path = 'examples/CCDG_14151_B01_GRM_WGS_2020-08-05_chr19.filtered.shapeit2-duohmm-phased.2504.43-47Mb.ALL.maf01.haps.gz'\n",
    "sample_f_path = 'examples/CCDG_14151_B01_GRM_WGS_2020-08-05_chr19.filtered.shapeit2-duohmm-phased.2504.43-47Mb.ALL.maf01.sample.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "848d2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_numSNPs = 26246\n",
    "examined_numSNPs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5da961c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "start_row = random.randint(0,total_numSNPs-examined_numSNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1085dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "771954de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(hap_f_path,header=None,sep=' ',skiprows=start_row,nrows=examined_numSNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "066ec3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_pos = df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "403bb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure sort by position\n",
    "df = df.sort_values(by=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "03d42e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'training_data_{examined_numSNPs}.pkl','wb') as f:\n",
    "#     pickle.dump((df,start_row,examined_numSNPs),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "340f8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "haps = df.loc[:,5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bd0b22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(haps.shape[1]//2):\n",
    "    labels.append((haps[:,i],haps[:,haps.shape[1]//2+i]))\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3a110b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "genos = np.full(shape=(haps.shape[0],haps.shape[1]//2),fill_value=-1,dtype=int)\n",
    "## create genotypes by combining each pair of haplotypes\n",
    "for i in range(genos.shape[1]):\n",
    "    genos[:,i] = haps[:,2*i] + haps[:,2*i+1]\n",
    "genos = genos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c6200298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2504, 50)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "acd0aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a27c45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_possible_haps(genotypes):\n",
    "    all_possible_haps = set()\n",
    "    all_possible_dips = set()\n",
    "    num_samples,num_SNPs = genotypes.shape\n",
    "    for i in range(num_samples):\n",
    "        this_sample_possible_haps = [()]\n",
    "        for j in range(num_SNPs):\n",
    "            if genotypes[i,j] == 2:\n",
    "                for k in range(len(this_sample_possible_haps)):\n",
    "                    this_sample_possible_haps[k]+=(1,)\n",
    "            elif genotypes[i,j] == 0:\n",
    "                for k in range(len(this_sample_possible_haps)):\n",
    "                    this_sample_possible_haps[k]+=(0,)\n",
    "            else:\n",
    "                new_this_sample_possible_haps = []\n",
    "                previous_all_haps = this_sample_possible_haps.copy()\n",
    "                for k in range(len(previous_all_haps)):\n",
    "                    previous_all_haps[k]+=(1,)\n",
    "                new_this_sample_possible_haps += previous_all_haps\n",
    "                previous_all_haps = this_sample_possible_haps.copy()\n",
    "                for k in range(len(previous_all_haps)):\n",
    "                    previous_all_haps[k]+=(0,)\n",
    "                new_this_sample_possible_haps += previous_all_haps\n",
    "                this_sample_possible_haps = new_this_sample_possible_haps\n",
    "        if len(this_sample_possible_haps) == 1:\n",
    "            hap = this_sample_possible_haps[0]\n",
    "            all_possible_haps.add(hap)\n",
    "            all_possible_dips.add((hap,hap))\n",
    "        else:\n",
    "            for l in range(len(this_sample_possible_haps)//2):\n",
    "                hap_1 = this_sample_possible_haps[l] \n",
    "                hap_2 = this_sample_possible_haps[len(this_sample_possible_haps)-l-1] \n",
    "                all_possible_haps.add(hap_1)\n",
    "                all_possible_haps.add(hap_2)\n",
    "                if hap_1<= hap_2:\n",
    "                    all_possible_dips.add((hap_1,hap_2))\n",
    "                else:\n",
    "                    all_possible_dips.add((hap_2,hap_1))\n",
    "#     all_possible_dips = set(all_possible_dips)\n",
    "#     reverse_all_possible_haps_index = {}\n",
    "#     for hap,index in all_possible_haps_index.items():\n",
    "#         reverse_all_possible_haps_index[index] = hap\n",
    "    return list(all_possible_dips),list(all_possible_haps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3cb04fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class haplotypeSegmentGraph(object):\n",
    "    '''\n",
    "    H_g\n",
    "    '''\n",
    "    def __init__(self,genos,genetic_pos,B):\n",
    "        '''\n",
    "        B: number of hetero markers in each segment\n",
    "        '''\n",
    "        self.nodes = {}\n",
    "        self.genetic_pos = genetic_pos\n",
    "        self.B = B\n",
    "        self.total_num_haplotypes = None\n",
    "        self.build_haplotype_graph(genos)\n",
    "    def __str__(self):\n",
    "        nodes_count = 0\n",
    "        for marker,nodes in self.nodes.items():\n",
    "            nodes_count += len(nodes)\n",
    "        log_num_haps = math.log(self.total_num_haplotypes)/math.log(2)\n",
    "        output = f'''===========================\n",
    "Number of haplotypes: {self.total_num_haplotypes} (~2^{log_num_haps})\n",
    "Number of markers: {len(self.nodes)}\n",
    "Number of nodes (# segment haplotypes(~=B) x # markers): {nodes_count}\n",
    "==========================='''\n",
    "        return output\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def build_haplotype_graph(self,genos):\n",
    "        B = self.B\n",
    "        masking = genos.copy()\n",
    "        masking[masking!=1] =0\n",
    "        snp_hetero = masking.max(axis=0)\n",
    "        cumsum_snp_hetero = np.cumsum(snp_hetero)\n",
    "        bins = np.array([i*B for i in range(int(cumsum_snp_hetero[-1]//B)+1)])\n",
    "        inds = np.digitize(cumsum_snp_hetero, bins,right=True)\n",
    "        \n",
    "        # for each segment\n",
    "        marker_id = genos.shape[1]\n",
    "        after_marker_nodes = []\n",
    "        node_id = 0\n",
    "        for unique_ind in np.unique(inds)[::-1]:\n",
    "            segment_genos = genos[:,inds==unique_ind]\n",
    "            dips,haps = construct_possible_haps(segment_genos)\n",
    "            last_marker = True\n",
    "            for i in list(range(segment_genos.shape[1]))[::-1]:\n",
    "                marker_id -= 1\n",
    "                marker_nodes = []\n",
    "                for hap in haps:\n",
    "                    assert len(hap) == segment_genos.shape[1]\n",
    "                    pos = self.genetic_pos[marker_id]\n",
    "                    node = haplotypeSegmentNode(node_id,marker_id,hap,hap[i],pos)\n",
    "                    node_id += 1\n",
    "                    marker_nodes.append(node)\n",
    "#                     if len(after_marker_nodes) == 0:\n",
    "#                         print(marker_id+1)\n",
    "                    if last_marker:\n",
    "                        node.type = 'inter'\n",
    "                        node.outer_nodes = after_marker_nodes\n",
    "                        for outer_node in node.outer_nodes:\n",
    "                            outer_node.inner_nodes.append(node)\n",
    "                    else:\n",
    "                        node.type = 'intra'\n",
    "                        node.outer_nodes = [n for n in after_marker_nodes if n.haplotype==node.haplotype]\n",
    "                        for outer_node in node.outer_nodes:\n",
    "                            outer_node.inner_nodes.append(node)\n",
    "                after_marker_nodes = marker_nodes\n",
    "                last_marker = False\n",
    "                self.nodes[marker_id] = after_marker_nodes\n",
    "        total_num_haplotypes = 0\n",
    "        for node in self.nodes[0]:\n",
    "            total_num_haplotypes += self.forward(node)\n",
    "        self.total_num_haplotypes = total_num_haplotypes\n",
    "        for node in self.nodes[genos.shape[1]-1]:\n",
    "            self.backward(node)\n",
    "        for node in self.nodes[0]:\n",
    "            self.update_weight(node)\n",
    "        \n",
    "    def forward(self,node):\n",
    "        if len(node.outer_nodes) == 0:\n",
    "            node.outer_weight = 1\n",
    "            return 1\n",
    "        else:\n",
    "            all_num_outer_haplotypes  = 0\n",
    "            for outer_node in node.outer_nodes:\n",
    "                if outer_node.outer_weight == None:\n",
    "                    all_num_outer_haplotypes += self.forward(outer_node)\n",
    "                else:\n",
    "                    all_num_outer_haplotypes += outer_node.outer_weight\n",
    "            node.outer_weight = all_num_outer_haplotypes\n",
    "            return all_num_outer_haplotypes\n",
    "    def backward(self,node):\n",
    "        if len(node.inner_nodes) == 0:\n",
    "            node.inner_weight = 1\n",
    "            return 1\n",
    "        else:\n",
    "            all_num_inner_haplotypes  = 0\n",
    "            for inner_node in node.inner_nodes:\n",
    "                if inner_node.inner_weight == None:\n",
    "                    all_num_inner_haplotypes += self.backward(inner_node)\n",
    "                else:\n",
    "                    all_num_inner_haplotypes += inner_node.inner_weight\n",
    "            node.inner_weight = all_num_inner_haplotypes\n",
    "            return all_num_inner_haplotypes\n",
    "    def update_weight(self,node):\n",
    "        if node.weight == None:\n",
    "            node.weight = node.inner_weight * node.outer_weight\n",
    "            for outer_node in node.outer_nodes:\n",
    "                node.outer_weights[outer_node.id] = node.inner_weight*outer_node.outer_weight\n",
    "                self.update_weight(outer_node)\n",
    "        \n",
    "class haplotypeSegmentNode(object):\n",
    "    def __init__(self,node_id,marker,haplotype,allele,pos):\n",
    "        self.id = node_id\n",
    "        self.marker =  marker\n",
    "        self.haplotype = haplotype\n",
    "        self.allele = allele\n",
    "        self.weight = None\n",
    "        self.inner_weight = None\n",
    "        self.outer_weight = None\n",
    "        self.type = None\n",
    "        self.inner_nodes = []\n",
    "        self.outer_nodes = []\n",
    "        self.outer_weights = {}\n",
    "        self.pos = pos\n",
    "    def __str__(self):\n",
    "        log_weight = math.log(self.weight)/math.log(2)\n",
    "        log_inner_weight = math.log(self.inner_weight)/math.log(2)\n",
    "        log_outer_weight = math.log(self.outer_weight)/math.log(2)\n",
    "        output = f'''===========================\n",
    "Haplotype segment Node: represents a possible haplotype state for this marker in the whole dataset\n",
    "--------------------------\n",
    "Node id: {self.id}\n",
    "Marker id: {self.marker}\n",
    "Haplotype: {self.haplotype}\n",
    "Allele: {self.allele}\n",
    "Type(it connects to another segment[inter] or connects to the node in the same segment[intra]): {self.type}\n",
    "Weight (# haplotypes going through this node): {self.weight}(~2^{log_weight})\n",
    "Inner weight(# haplotypes ending at this node): {self.inner_weight} (~2^{log_inner_weight})\n",
    "Outer weight weight(# haplotypes starting from this node): {self.outer_weight} (~2^{log_outer_weight})\n",
    "# inner nodes (# nodes connect to it): {len(self.inner_nodes)}\n",
    "# outer nodes (# nodes it connects to): {len(self.outer_nodes)}\n",
    "Genetic position: {self.pos}\n",
    "==========================='''\n",
    "        return output\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def dist(self,another_node):\n",
    "        return np.abs(self.pos - another_node.pos)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "80625822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class genoSegmentGraph(object):\n",
    "    '''\n",
    "    S_g graph\n",
    "    '''\n",
    "    def __init__(self,geno,B):\n",
    "        self.nodes = {}\n",
    "        self.B = B\n",
    "        self.build_geno_graph(geno)\n",
    "    def __str__(self):\n",
    "        nodes_count = 0\n",
    "        for marker,nodes in self.nodes.items():\n",
    "            nodes_count += len(nodes)\n",
    "        \n",
    "        output = f'''===========================\n",
    "Number of markers: {len(self.nodes)}\n",
    "Number of nodes (# segment haplotypes(~=B) x # markers): {nodes_count}\n",
    "==========================='''\n",
    "        return output\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def build_geno_graph(self,geno):\n",
    "        '''\n",
    "        B: number of hetero markers in each segment\n",
    "        geno: genotype (num_of_markers)\n",
    "        '''\n",
    "        B = self.B\n",
    "        # split the genotype by segments\n",
    "        splitted_geno = np.split(geno, np.where(geno == 1)[0][:-1]+1)\n",
    "        segments = [np.concatenate(splitted_geno[i:i+B]) for i in range(0,len(splitted_geno),B)]\n",
    "        marker_id = geno.shape[0]\n",
    "        after_marker_nodes = []\n",
    "        node_id = 0\n",
    "        for segment in segments[::-1]:\n",
    "            segment_geno = np.array([segment])\n",
    "            _,haps = construct_possible_haps(segment_geno)\n",
    "            last_marker = True\n",
    "            for i in list(range(segment_geno.shape[1]))[::-1]:\n",
    "                marker_id -= 1\n",
    "                marker_nodes = []\n",
    "                for hap in haps:\n",
    "                    node = genoSegmentNode(node_id,marker_id,hap,hap[i],segment)\n",
    "                    node_id += 1\n",
    "                    marker_nodes.append(node)\n",
    "                    if last_marker:\n",
    "                        node.type = 'inter'\n",
    "                        node.outer_nodes = after_marker_nodes\n",
    "                        for outer_node in node.outer_nodes:\n",
    "                            outer_node.inner_nodes.append(node)\n",
    "                    else:\n",
    "                        node.type = 'intra'\n",
    "                        node.outer_nodes = [n for n in after_marker_nodes if n.haplotype==node.haplotype]\n",
    "                        for outer_node in node.outer_nodes:\n",
    "                            outer_node.inner_nodes.append(node)\n",
    "                if last_marker and after_marker_nodes == []:\n",
    "                    leaves_nodes = marker_nodes\n",
    "                after_marker_nodes = marker_nodes\n",
    "                last_marker = False\n",
    "                self.nodes[marker_id] = after_marker_nodes\n",
    "class genoSegmentNode(object):\n",
    "    def __init__(self,node_id,marker,haplotype,allele,segment):\n",
    "        self.id = node_id\n",
    "        self.marker =  marker\n",
    "        self.haplotype = haplotype\n",
    "        self.allele = allele\n",
    "        self.segment = segment\n",
    "        self.type = None\n",
    "        self.inner_nodes = []\n",
    "        self.outer_nodes = []\n",
    "    def __str__(self):\n",
    "        output = f'''===========================\n",
    "Geno segment Node: represents a possible haplotype state for this marker in this sample genotype\n",
    "--------------------------\n",
    "Node id: {self.id}\n",
    "Marker id: {self.marker}\n",
    "Haplotype: {self.haplotype}\n",
    "Segment genotype: {self.segment}\n",
    "Allele: {self.allele}\n",
    "Type(it connects to another segment[inter] or connects to the node in the same segment[intra]): {self.type}\n",
    "# inner nodes (# nodes connect to it): {len(self.inner_nodes)}\n",
    "# outer nodes (# nodes it connects to): {len(self.outer_nodes)}\n",
    "==========================='''\n",
    "        return output\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8043a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "class haplotypeHMM(object):\n",
    "    '''\n",
    "    hidden_states -> mosaic state (X,Y), indicating states of diploids from haplotypes X and Y\n",
    "    transition -> transition prob for mosaic state\n",
    "    emission -> prob of genotype condition on mosaic state\n",
    "    inital -> prob initial mosaic state\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, hap_graph,savedir='./checkpoints/',pseudocount=1e-100,seed=42):\n",
    "        self.hap_graph = hap_graph\n",
    "        self.B = self.hap_graph.B\n",
    "        self.total_num_haplotypes = self.hap_graph.total_num_haplotypes\n",
    "        self.seed = seed\n",
    "        self.pseudocount = pseudocount\n",
    "        K = self.total_num_haplotypes\n",
    "        self.theta = 1/(math.log(K) + 0.5772)\n",
    "        self.population_size = 15000\n",
    "        self.savedir = savedir\n",
    "#     def emit_prob(self, this_state, haplotype):\n",
    "#         return self.emissions[this_state][haplotype]\n",
    "    \n",
    "#     def transition_prob(self, this_state, next_state):\n",
    "#         return self.transitions[this_state][next_state]\n",
    "    \n",
    "#     def init_prob(self, this_state):\n",
    "#         return self.initial[this_state]\n",
    "\n",
    "    def emit_prob(self, this_node, geno_graph_node):\n",
    "        K = self.total_num_haplotypes\n",
    "        theta = self.theta\n",
    "        if geno_graph_node.allele == this_node.allele:\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = 0\n",
    "        prob = K/(K+theta) * delta + theta/(K+theta)/2\n",
    "        assert prob >= 0 and prob <= 1\n",
    "        if prob == 0:\n",
    "            prob = self.pseudocount\n",
    "        if prob == 1:\n",
    "            prob -= self.pseudocount\n",
    "        return prob\n",
    "#         return self.emissions[this_node][genotype]\n",
    "    \n",
    "    def transition_prob(self, this_node, next_node):\n",
    "        K = self.total_num_haplotypes\n",
    "        rho = 1 - np.exp(-4*self.population_size*this_node.dist(next_node)/K)\n",
    "        if next_node.id in this_node.outer_weights:\n",
    "            edge_weight = this_node.outer_weights[next_node.id]\n",
    "        else:\n",
    "            edge_weight = 0\n",
    "        prob = (1-rho) * edge_weight / this_node.weight + rho * next_node.weight / self.total_num_haplotypes\n",
    "        assert prob >= 0 and prob <= 1\n",
    "        if prob == 0:\n",
    "            prob = self.pseudocount\n",
    "        if prob == 1:\n",
    "            prob -= self.pseudocount\n",
    "        return prob\n",
    "    \n",
    "    def init_prob(self, node):\n",
    "        prob = node.weight / self.total_num_haplotypes\n",
    "        assert prob >= 0 and prob <= 1\n",
    "        if prob == 0:\n",
    "            prob = self.pseudocount\n",
    "        if prob == 1:\n",
    "            prob -= self.pseudocount\n",
    "        return prob\n",
    "    \n",
    "    def logsumexp(self,lst):\n",
    "        arr = np.array(lst)\n",
    "#         log_arr =np.log(arr)\n",
    "#         if np.any(arr<=0):\n",
    "#             print(arr)\n",
    "#             raise Exception()\n",
    "        return logsumexp(arr)\n",
    "    def forward(self, geno_graph):\n",
    "        log_left_list = []\n",
    "        log_left = np.empty(shape=(len(geno_graph.nodes[0]),len(self.hap_graph.nodes[0])))\n",
    "        # for first marker\n",
    "        for i,geno_graph_node in enumerate(geno_graph.nodes[0]):\n",
    "            for j,hap_graph_node in enumerate(self.hap_graph.nodes[0]):\n",
    "                log_left[i,j] = np.log(self.init_prob(hap_graph_node)) + np.log(self.emit_prob(hap_graph_node, geno_graph_node))\n",
    "        log_left_list.append(log_left)\n",
    "        all_marker_id = list(sorted(hap_graph.nodes.keys()))\n",
    "        for marker_id in all_marker_id[1:]:\n",
    "            log_left = np.empty(shape=(len(geno_graph.nodes[marker_id]),len(self.hap_graph.nodes[marker_id])))\n",
    "            for i,geno_graph_node in enumerate(geno_graph.nodes[marker_id]):\n",
    "                for j,hap_graph_node in enumerate(self.hap_graph.nodes[marker_id]):\n",
    "                    all_temp_log_left = []\n",
    "                    for u,prev_geno_graph_node in enumerate(geno_graph.nodes[marker_id-1]):\n",
    "                        if prev_geno_graph_node in geno_graph_node.inner_nodes:\n",
    "                            for v,prev_hap_graph_node in enumerate(self.hap_graph.nodes[marker_id-1]):\n",
    "                                all_temp_log_left.append(log_left_list[marker_id-1][u,v] +  np.log(self.transition_prob(prev_hap_graph_node,hap_graph_node)))\n",
    "                    \n",
    "                    log_left[i,j] = np.log(self.emit_prob(hap_graph_node, geno_graph_node)) + self.logsumexp(all_temp_log_left)\n",
    "            log_left_list.append(log_left)\n",
    "        return log_left_list\n",
    "    def backward(self, geno_graph):\n",
    "        log_right_list = []\n",
    "        log_right = np.empty(shape=(len(geno_graph.nodes[0]),len(self.hap_graph.nodes[0])))\n",
    "        # for last marker\n",
    "        all_marker_id = list(sorted(hap_graph.nodes.keys()))\n",
    "        marker_id = all_marker_id[-1]\n",
    "        for i,geno_graph_node in enumerate(geno_graph.nodes[marker_id]):\n",
    "            for j,hap_graph_node in enumerate(self.hap_graph.nodes[marker_id]):\n",
    "                log_right[i,j] = 0\n",
    "        log_right_list.insert(0,log_right)\n",
    "        for marker_id in all_marker_id[-2::-1]:\n",
    "            log_right = np.empty(shape=(len(geno_graph.nodes[marker_id]),len(self.hap_graph.nodes[marker_id])))\n",
    "            for i,geno_graph_node in enumerate(geno_graph.nodes[marker_id]):\n",
    "                for j,hap_graph_node in enumerate(self.hap_graph.nodes[marker_id]):\n",
    "                    all_temp_log_right = []\n",
    "                    for u,next_geno_graph_node in enumerate(geno_graph.nodes[marker_id+1]):\n",
    "                        if next_geno_graph_node in geno_graph_node.outer_nodes:\n",
    "                            for v,next_hap_graph_node in enumerate(self.hap_graph.nodes[marker_id+1]):\n",
    "                                all_temp_log_right.append(log_right_list[0][u,v] +  np.log(self.transition_prob(hap_graph_node,next_hap_graph_node)))\n",
    "                    \n",
    "                    log_right[i,j] = np.log(self.emit_prob(hap_graph_node, geno_graph_node)) + self.logsumexp(all_temp_log_right)\n",
    "            log_right_list.insert(0,log_right)\n",
    "        return log_right_list\n",
    "    def expectation(self,geno_graph):\n",
    "        log_alpha_list = self.forward(geno_graph)\n",
    "        log_beta_list = self.backward(geno_graph)\n",
    "        \n",
    "        all_marker_id = list(sorted(hap_graph.nodes.keys()))\n",
    "        marker_id = all_marker_id[0]\n",
    "        init_log_marginal = np.empty(shape=(len(geno_graph.nodes[marker_id])))\n",
    "        for i,geno_graph_node in enumerate(geno_graph.nodes[marker_id]):\n",
    "            init_log_marginal[i] = self.logsumexp(log_beta_list[0][i,:]) - self.logsumexp(log_beta_list[0])\n",
    "        \n",
    "        log_marginal_list = [init_log_marginal]\n",
    "        for marker_id in all_marker_id[0:-1]:\n",
    "            log_marginal = np.empty(shape=(len(geno_graph.nodes[marker_id]),len(geno_graph.nodes[marker_id+1])))\n",
    "            temp_log_marginal = []\n",
    "            for i1,geno_graph_node_1 in enumerate(geno_graph.nodes[marker_id]):\n",
    "                for i2,geno_graph_node_2 in enumerate(geno_graph.nodes[marker_id+1]):\n",
    "                    for j1,hap_graph_node_1 in enumerate(self.hap_graph.nodes[marker_id]):\n",
    "                        for j2,hap_graph_node_2 in enumerate(self.hap_graph.nodes[marker_id+1]):\n",
    "                            temp_log_marginal.append(log_alpha_list[marker_id][i1,j1] + np.log(self.transition_prob(hap_graph_node_1,hap_graph_node_2))+\\\n",
    "                            np.log(self.emit_prob(hap_graph_node_2,geno_graph_node_2)) + log_beta_list[marker_id+1][i2,j2])\n",
    "            index = 0\n",
    "            for i1,geno_graph_node_1 in enumerate(geno_graph.nodes[marker_id]):\n",
    "                for i2,geno_graph_node_2 in enumerate(geno_graph.nodes[marker_id+1]):\n",
    "                    log_marginal[i1,i2] = temp_log_marginal[index] - self.logsumexp(temp_log_marginal)\n",
    "                    index += 1\n",
    "            log_marginal_list.append(log_marginal)\n",
    "        return log_marginal_list\n",
    "                            \n",
    "                            \n",
    "            \n",
    "    \n",
    "#     def check_convergence(self,this_px,previous_px,eps):\n",
    "#         if np.linalg.norm(np.array(this_px) - np.array(previous_px))/np.linalg.norm(np.array(previous_px)) < eps:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     def check_compatible_with_genotype(self,genotype,hap_1,hap_2):\n",
    "#         assert len(hap_1) == len(hap_2) == len(genotype) \n",
    "#         incompatible_snps = 0\n",
    "#         for i in range(len(genotype)):\n",
    "#             if  hap_1[i] + hap_2[i] != genotype[i]:\n",
    "#                 incompatible_snps += 1\n",
    "#         return incompatible_snps\n",
    "    \n",
    "#     def predict(self,geno_graph_nodes):\n",
    "#         initials = np.empty((num_states))\n",
    "#         transitions = np.empty((num_states,num_states))\n",
    "        \n",
    "    def predict(self,genos,choice='Viterbi',threads=1):\n",
    "        if choice == 'Viterbi':\n",
    "            genos_list = [geno for geno in genos]\n",
    "#             with Pool(threads) as p:\n",
    "#                 predictions = p.map(self.predict_Viterbi, genos_list)\n",
    "            \n",
    "            predictions = Parallel(n_jobs=threads)(delayed(self.predict_Viterbi)(geno) for geno in genos_list)\n",
    "        return np.array(predictions)\n",
    "\n",
    "#     def save_checkpoint(self,check_point_folder,it):\n",
    "#         Path(check_point_folder).mkdir(exist_ok=True,parents=True)\n",
    "#         timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#         with open(check_point_folder+f'/{it}_{timestr}.pt','wb') as f:\n",
    "#             pickle.dump(self,f)\n",
    "#     def predict_Viterbi(self, geno,geno_graph,log_marginal_list):\n",
    "#         # Predict by Viterbi\n",
    "#         previous_col_probs = {}\n",
    "#         for i in range(log_marginal_list[0].shape[0]):\n",
    "#             previous_col_probs[i] = log_marginal_list[0][i]\n",
    "#         traceback = []\n",
    "\n",
    "#         for t in range(1, len(log_marginal_list)): \n",
    "#             marker_id = t - 1\n",
    "#             traceback_next = {}\n",
    "#             previous_col_probs_next = {}\n",
    "#             for i1,geno_graph_node in enumerate(geno_graph.nodes[marker_id]):\n",
    "#                 k = previous_col_probs[i1] + log_marginal_list[t][i1,:]\n",
    "#                 for i2,geno_graph_node in enumerate(geno_graph.nodes[marker_id+1]):\n",
    "# #                     if geno[marker_id] >= \n",
    "#                     argmax_i2 = np.argmax(k)\n",
    "#                 traceback_next[i1] = argmax_i2\n",
    "#                 previous_col_probs_next[i1] = k[argmax_i2]\n",
    "#             traceback.append(traceback_next)\n",
    "#             previous_col_probs = previous_col_probs_next\n",
    "            \n",
    "\n",
    "#         max_final_state = None\n",
    "#         max_final_prob = -np.inf\n",
    "#         for state,prob in previous_col_probs.items():\n",
    "#             if prob > max_final_prob:\n",
    "#                 max_final_prob = prob\n",
    "#                 max_final_state = state\n",
    "#         all_marker_id = list(sorted(hap_graph.nodes.keys()))\n",
    "#         result = [geno_graph.nodes[len(all_marker_id)-1][max_final_state]]\n",
    "#         for t in range(len(all_marker_id)-2,-1,-1):\n",
    "#             marker_id = all_marker_id[t]\n",
    "#             result.append(geno_graph.nodes[marker_id][traceback[t][max_final_state]])\n",
    "#             max_final_state = traceback[t][max_final_state]\n",
    "\n",
    "#         return result[::-1]\n",
    "    def predict_Viterbi(self, geno):\n",
    "        geno_graph = genoSegmentGraph(geno,self.B)\n",
    "        log_marginal_list = hmm.expectation(geno_graph)\n",
    "        \n",
    "        # Predict by Viterbi\n",
    "        previous_col_probs = {}\n",
    "        for i in range(log_marginal_list[0].shape[0]):\n",
    "            for j in range(log_marginal_list[0].shape[0]):\n",
    "                previous_col_probs[(i,j)] = log_marginal_list[0][i] + log_marginal_list[0][j]\n",
    "        traceback = []\n",
    "        incompatible_penalty = 0.1\n",
    "        all_marker_id = list(sorted(geno_graph.nodes.keys()))\n",
    "        for t in range(1, len(log_marginal_list)): \n",
    "            marker_id = all_marker_id[t-1]\n",
    "            traceback_next = {}\n",
    "            previous_col_probs_next = {}\n",
    "            # next state\n",
    "            for hap1_i2,hap1_geno_graph_node_i2 in enumerate(geno_graph.nodes[marker_id+1]):\n",
    "                for hap2_i2,hap2_geno_graph_node_i2 in enumerate(geno_graph.nodes[marker_id+1]):\n",
    "                        \n",
    "                    best_prob = -np.inf\n",
    "                    best_haps = None\n",
    "                    # prev state\n",
    "                    for hap1_i1,hap1_geno_graph_node_i1 in enumerate(geno_graph.nodes[marker_id]):\n",
    "                        for hap2_i1,hap2_geno_graph_node_i1 in enumerate(geno_graph.nodes[marker_id]):\n",
    "\n",
    "                            num_mismatches = np.abs(geno[marker_id] - (hap1_geno_graph_node_i1.allele + hap2_geno_graph_node_i1.allele)) + np.abs(geno[marker_id+1] - (hap1_geno_graph_node_i2.allele + hap2_geno_graph_node_i2.allele))\n",
    "                            prob = previous_col_probs[(hap1_i1,hap2_i1)] + log_marginal_list[t][hap1_i1,hap1_i2] + \\\n",
    "                            log_marginal_list[t][hap2_i1,hap2_i2]\n",
    "                            prob *= 1+incompatible_penalty * num_mismatches\n",
    "                            if prob > best_prob:\n",
    "                                best_prob = prob\n",
    "                                best_haps = (hap1_i1,hap2_i1)\n",
    "                    if best_haps != None:\n",
    "                        traceback_next[(hap1_i2,hap2_i2)] = best_haps\n",
    "                        previous_col_probs_next[(hap1_i2,hap2_i2)] = best_prob\n",
    "            previous_col_probs = previous_col_probs_next\n",
    "            traceback.append(traceback_next)\n",
    "            \n",
    "\n",
    "        max_final_state = None\n",
    "        max_final_prob = -np.inf\n",
    "        for state,prob in previous_col_probs.items():\n",
    "            if prob > max_final_prob:\n",
    "                max_final_prob = prob\n",
    "                max_final_state = state\n",
    "        \n",
    "        nodes = geno_graph.nodes[all_marker_id[-1]]\n",
    "#         if max_final_state[0] >= len(nodes) or max_final_state[1] >= len(nodes):\n",
    "#             return geno,geno_graph,log_marginal_list\n",
    "        result = [(nodes[max_final_state[0]],nodes[max_final_state[1]])]\n",
    "        for t in range(len(all_marker_id)-2,-1,-1):\n",
    "            marker_id = all_marker_id[t]\n",
    "            nodes = geno_graph.nodes[marker_id]\n",
    "            max_final_state = traceback[t][max_final_state]\n",
    "            result.append((nodes[max_final_state[0]],nodes[max_final_state[1]]))\n",
    "        results = result[::-1]\n",
    "        hap1 = []\n",
    "        hap2 = []\n",
    "        for (hap1_node,hap2_node) in results:\n",
    "            if hap1_node.type == 'inter':\n",
    "                hap1 += hap1_node.haplotype\n",
    "            if hap2_node.type == 'inter':\n",
    "                hap2 += hap2_node.haplotype\n",
    "        return [hap1,hap2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cdeb0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_graph = haplotypeSegmentGraph(genos,genetic_pos,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "631c5b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================\n",
       "Number of haplotypes: 471415610408960 (~2^48.74399286106018)\n",
       "Number of markers: 50\n",
       "Number of nodes (# segment haplotypes(~=B) x # markers): 374\n",
       "==========================="
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0c13b474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================\n",
       "Haplotype segment Node: represents a possible haplotype state for this marker in the whole dataset\n",
       "--------------------------\n",
       "Node id: 366\n",
       "Marker id: 0\n",
       "Haplotype: (1, 0, 1)\n",
       "Allele: 1\n",
       "Type(it connects to another segment[inter] or connects to the node in the same segment[intra]): intra\n",
       "Weight (# haplotypes going through this node): 58926951301120(~2^45.74399286106018)\n",
       "Inner weight(# haplotypes ending at this node): 1 (~2^0.0)\n",
       "Outer weight weight(# haplotypes starting from this node): 58926951301120 (~2^45.74399286106018)\n",
       "# inner nodes (# nodes connect to it): 0\n",
       "# outer nodes (# nodes it connects to): 1\n",
       "Genetic position: 43959977\n",
       "==========================="
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap_graph.nodes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3e1a08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = haplotypeHMM(hap_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f86b5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     geno_graph = genoSegmentGraph(genos[:,10])\n",
    "#     geno_graph.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "752cab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hmm.predict(genos,threads=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "74e851a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_switch_error(prediction,truth):\n",
    "    SERs = []\n",
    "    hetero_masking = truth[0] + truth[1] == 1\n",
    "    hetero_prediction = prediction[0][hetero_masking]\n",
    "    hetero_truth = truth[0][hetero_masking]\n",
    "    if hetero_truth.shape[0] == 0:\n",
    "        return 0\n",
    "    hap_type = hetero_prediction == hetero_truth\n",
    "    num_switch = 0\n",
    "    for i in range(len(hap_type)-1):\n",
    "        if hap_type[i] != hap_type[i+1]:\n",
    "            num_switch += 1\n",
    "    SERs.append(num_switch/hap_type.shape[0])\n",
    "    \n",
    "    hetero_prediction = prediction[1][hetero_masking]\n",
    "    hetero_truth = truth[0][hetero_masking]\n",
    "    if hetero_truth.shape[0] == 0:\n",
    "        return 0\n",
    "    hap_type = hetero_prediction == hetero_truth\n",
    "    num_switch = 0\n",
    "    for i in range(len(hap_type)-1):\n",
    "        if hap_type[i] != hap_type[i+1]:\n",
    "            num_switch += 1\n",
    "    SERs.append(num_switch/hap_type.shape[0])\n",
    "    \n",
    "    return np.min(SERs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8b87bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_switch_error_rate(results,labels):\n",
    "    all_SER = []\n",
    "    for i in range(len(results)):\n",
    "        SER = get_switch_error(results[i],labels[i])\n",
    "        all_SER.append(SER)\n",
    "    return all_SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8f6527f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SER = calculate_switch_error_rate(results,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "867aa262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(all_SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def initialize_HMM_parameters_MACH(self, alphabet, states,seed):\n",
    "\n",
    "#         theta = epsi = 0.01\n",
    "#         H = len(self.haplotypes)\n",
    "#         transitions = {}\n",
    "#         emissions = {}\n",
    "#         initial = {}\n",
    "#         np.random.seed(seed=seed)\n",
    "#         initial_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "#         for i, state in enumerate(self.get_diplotypes()):\n",
    "#             transitions[state] = {}\n",
    "#             emissions[state] = {}\n",
    "#             initial[state] = initial_rand[i]\n",
    "#             # update emission matrix\n",
    "#             for j,geno in enumerate(self.get_genotypes()):\n",
    "#                 if geno ==1:\n",
    "#                     emissions[state][geno] = emissions_rand[j]\n",
    "                \n",
    "#             # update transition matrix\n",
    "#             state_x, state_y = state\n",
    "#             for j, next_state in enumerate(self.get_diplotypes()):\n",
    "#                 next_state_x,next_state_y = next_state\n",
    "#                 if (state_X != next_state_x) and (state_Y != next_state_y):\n",
    "#                     transitions[state][next_state] =  theta**2/H**2\n",
    "#                 elif (state_X != next_state_x) or (state_Y != next_state_y):\n",
    "#                     transitions[state][next_state] =  (1-theta) * theta/H + theta**2/(H**2)\n",
    "#                 else:\n",
    "#                     transitions[state][next_state] =  (1-theta) ** 2+ 2*(1-theta)*theta/H + theta**2/(H**2)\n",
    "#         return transitions,emissions,initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e92fb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_possible_haps(genotypes):\n",
    "    all_possible_haps_index = {}\n",
    "    all_possible_dips = []\n",
    "    num_samples,num_SNPs = genotypes.shape\n",
    "    for i in range(num_samples):\n",
    "        this_sample_possible_haps = [()]\n",
    "        for j in range(num_SNPs):\n",
    "            if genotypes[i,j] == 2:\n",
    "                for k in range(len(this_sample_possible_haps)):\n",
    "                    this_sample_possible_haps[k]+=(1,)\n",
    "            elif genotypes[i,j] == 0:\n",
    "                for k in range(len(this_sample_possible_haps)):\n",
    "                    this_sample_possible_haps[k]+=(0,)\n",
    "            else:\n",
    "                new_this_sample_possible_haps = []\n",
    "                previous_all_haps = this_sample_possible_haps.copy()\n",
    "                for k in range(len(previous_all_haps)):\n",
    "                    previous_all_haps[k]+=(1,)\n",
    "                new_this_sample_possible_haps += previous_all_haps\n",
    "                previous_all_haps = this_sample_possible_haps.copy()\n",
    "                for k in range(len(previous_all_haps)):\n",
    "                    previous_all_haps[k]+=(0,)\n",
    "                new_this_sample_possible_haps += previous_all_haps\n",
    "                this_sample_possible_haps = new_this_sample_possible_haps\n",
    "        if len(this_sample_possible_haps) == 1:\n",
    "            hap = this_sample_possible_haps[0]\n",
    "            if hap not in all_possible_haps_index:\n",
    "                all_possible_haps_index[hap] = len(all_possible_haps_index)\n",
    "            all_possible_dips.append((all_possible_haps_index[hap],all_possible_haps_index[hap]))\n",
    "        else:\n",
    "            for l in range(len(this_sample_possible_haps)//2):\n",
    "                hap_1 = this_sample_possible_haps[l] \n",
    "                hap_2 = this_sample_possible_haps[len(this_sample_possible_haps)-l-1] \n",
    "                if hap_1 not in all_possible_haps_index:\n",
    "                    all_possible_haps_index[hap_1] = len(all_possible_haps_index)\n",
    "                if hap_2 not in all_possible_haps_index:\n",
    "                    all_possible_haps_index[hap_2] = len(all_possible_haps_index)\n",
    "                if all_possible_haps_index[hap_1]<= all_possible_haps_index[hap_2]:\n",
    "                    all_possible_dips.append((all_possible_haps_index[hap_1],all_possible_haps_index[hap_2]))\n",
    "                else:\n",
    "                    all_possible_dips.append((all_possible_haps_index[hap_2],all_possible_haps_index[hap_1]))\n",
    "    all_possible_dips = set(all_possible_dips)\n",
    "    reverse_all_possible_haps_index = {}\n",
    "    for hap,index in all_possible_haps_index.items():\n",
    "        reverse_all_possible_haps_index[index] = hap\n",
    "    return all_possible_haps_index,all_possible_dips,reverse_all_possible_haps_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "training_data = genos[:,:]\n",
    "possible_genotypes = [0,1,2]\n",
    "all_possible_haps_index,all_possible_dips,reverse_all_possible_haps_index = construct_possible_haps(training_data)\n",
    "model = haplotypeHMM(possible_genotypes, list(all_possible_dips),range(len(all_possible_haps_index)),reverse_all_possible_haps_index,savedir='./40_SNPs/',seed=70,pseudocount=1e-100)\n",
    "\n",
    "model.fit(training_data,100,1e-3)\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a07ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(training_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a24af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class haplotypeHMM(object):\n",
    "#     '''\n",
    "#     hidden_states -> mosaic state (X,Y), indicating states of diploids from haplotypes X and Y\n",
    "#     transition -> transition prob for mosaic state\n",
    "#     emission -> prob of genotype condition on mosaic state\n",
    "#     inital -> prob initial mosaic state\n",
    "    \n",
    "#     '''\n",
    "#     def __init__(self, genotypes, diplotypes, possible_haplotypes,seed=42,pseudocount=1e-100):\n",
    "#         self.genotypes = list(set(genotypes))\n",
    "#         self.diplotypes = list(set(hidden_states))\n",
    "#         self.haplotypes = possible_haplotypes\n",
    "#         self.seed = seed\n",
    "#         self.pseudocount = pseudocount\n",
    "#         self.transitions,self.emissions,self.initial = self.initialize_HMM_parameters_randomly(self.genotypes, self.diplotypes, self.seed)\n",
    "    \n",
    "#     def emit_prob(self, this_state, haplotype):\n",
    "#         return self.emissions[this_state][haplotype]\n",
    "    \n",
    "#     def transition_prob(self, this_state, next_state):\n",
    "#         return self.transitions[this_state][next_state]\n",
    "    \n",
    "#     def init_prob(self, this_state):\n",
    "#         return self.initial[this_state]\n",
    "\n",
    "#     def get_diplotypes(self):\n",
    "#         for state in self.diplotypes:\n",
    "#             yield state\n",
    "#     def get_genotypes(self):\n",
    "#         for genotype in self.genotypes:\n",
    "#             yield genotype\n",
    "#     def initialize_HMM_parameters_randomly(self, alphabet, states,seed):\n",
    "        \n",
    "#         transitions = {}\n",
    "#         emissions = {}\n",
    "#         initial = {}\n",
    "#         np.random.seed(seed=seed)\n",
    "#         initial_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "#         for i, state in enumerate(self.get_diplotypes()):\n",
    "#             transitions[state] = {}\n",
    "#             emissions[state] = {}\n",
    "#             initial[state] = initial_rand[i]\n",
    "#             emissions_rand = np.random.dirichlet(np.ones(len(self.genotypes)))\n",
    "#             transitions_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "#             for j,geno in enumerate(self.get_genotypes()):\n",
    "#                 emissions[state][geno] = emissions_rand[j]\n",
    "#             for j, next_state in enumerate(self.get_diplotypes()):\n",
    "#                 transitions[state][next_state] = transitions_rand[j]\n",
    "                \n",
    "#         return transitions,emissions,initial\n",
    "#     def log_sum_exp(self,x):\n",
    "#         x_arr = np.array(x)\n",
    "#         x_log_arr = np.log(x_arr)\n",
    "#         x_log_max = x_log_arr.max()\n",
    "#         return x_log_max + np.log(np.sum(np.e**(x_log_arr-x_log_max)))\n",
    "#     def sum_normalize(self,x):\n",
    "#         return np.exp(np.log(np.array(x))-self.log_sum_exp(x))\n",
    "#     def calculate_s_value(self, seq_pos, previous_vars,single_pos_genotype):\n",
    "#         \"\"\"Calculate the next scaling variable for a sequence position (PRIVATE).\n",
    "#         This utilizes the approach of choosing s values such that the\n",
    "#         sum of all of the scaled f values is equal to 1.\n",
    "#         Arguments:\n",
    "#          - seq_pos -- The current position we are at in the sequence.\n",
    "#          - previous_vars -- All of the forward or backward variables\n",
    "#            calculated so far.\n",
    "#         Returns:\n",
    "#          - The calculated scaling variable for the sequence item.\n",
    "#         \"\"\"\n",
    "#         # all of the different letters the state can have\n",
    "#         state_letters = self.get_diplotypes()\n",
    "\n",
    "#         # loop over all of the possible states\n",
    "#         s_value = 0\n",
    "#         for main_state in state_letters:\n",
    "#             emission = self.emit_prob(main_state,single_pos_genotype)\n",
    "\n",
    "#             # now sum over all of the previous vars and transitions\n",
    "#             trans_and_var_sum = 0\n",
    "#             for second_state in state_letters:\n",
    "#                 # the value of the previous f or b value\n",
    "#                 var_value = previous_vars[seq_pos - 1][second_state]\n",
    "\n",
    "#                 # the transition probability\n",
    "#                 trans_value = self.transition_prob(main_state,second_state)\n",
    "\n",
    "#                 trans_and_var_sum += var_value * trans_value\n",
    "\n",
    "#             s_value += emission * trans_and_var_sum\n",
    "\n",
    "#         return s_value\n",
    "#     def forward(self, genotype):\n",
    "#         left_list = []\n",
    "#         left = {}\n",
    "#         for state in self.get_diplotypes():\n",
    "#             left[state] = self.init_prob(state) * self.emit_prob(state, genotype[0])\n",
    "#         left_list.append(left)\n",
    "        \n",
    "#         for i in range(1, len(genotype)):\n",
    "#             s_value = self.calculate_s_value(i,left_list,genotype[i])\n",
    "#             left = {}\n",
    "#             for next_state in self.get_diplotypes(): \n",
    "#                 left[next_state] = 0\n",
    "#                 for this_state in self.get_diplotypes():\n",
    "#                     left[next_state] += left_list[i-1][this_state] * self.transition_prob(this_state, next_state) \n",
    "#                 left[next_state] =  self.emit_prob(next_state, genotype[i]) * left[next_state]\n",
    "#             for next_state in self.get_diplotypes():\n",
    "#                 left[next_state] /= s_value\n",
    "#             left_list.append(left)\n",
    "#         # rescale left\n",
    "# #         print('LEFT')\n",
    "# #         print(left_list)\n",
    "# #         print(scale_list)\n",
    "# #         for i in range(len(left_list)):\n",
    "# #             for state in self.get_diplotypes():\n",
    "# #                 left_list[i][state] *= np.sum(scale_list[:i+1])\n",
    "#         posterior = 0\n",
    "#         for state in self.get_diplotypes():\n",
    "#             posterior += left_list[-1][state]\n",
    "\n",
    "#         return posterior, left_list\n",
    "\n",
    "\n",
    "#     def backward(self, genotype):\n",
    "# #         scale_list = [1]\n",
    "#         right_list = [] \n",
    "#         right = {}\n",
    "#         for state in self.get_diplotypes():\n",
    "#             right[state] = 1\n",
    "#         right_list.append(right)\n",
    "\n",
    "#         for i in range(len(genotype)-2, -1, -1):\n",
    "#             s_value = self.calculate_s_value(len(genotype)-1-i,right_list[::-1],genotype[i])\n",
    "\n",
    "#             right = {} \n",
    "# #             scale = 0 \n",
    "#             for state in self.get_diplotypes():\n",
    "#                 right[state] = 0\n",
    "#                 for next_state in self.get_diplotypes():\n",
    "#                     right[state] += right_list[0][next_state] * self.transition_prob(state, next_state) * self.emit_prob(next_state, genotype[i])\n",
    "# #                     scale += right[state]\n",
    "# #             for state in self.get_diplotypes():\n",
    "# #                 right[state] /= (scale_list[i+1]-scale_list[i])\n",
    "# #             scale_list.insert(0,scale)\n",
    "#             right_list.insert(0,right)\n",
    "        \n",
    "#         # rescale left\n",
    "# #         print('RIGHT')\n",
    "# #         print(right_list)\n",
    "# #         print(scale_list)\n",
    "# #         scaled_right_list = right_list.copy()\n",
    "# #         for i in range(len(right_list)-1,-1,-1):\n",
    "# #             for state in self.get_diplotypes():\n",
    "# #                 right_list[i][state] *= np.sum(scale_list[i:])\n",
    "        \n",
    "#         posterior = 0\n",
    "#         for state in self.get_diplotypes():\n",
    "#             posterior += right_list[0][state] * self.init_prob(state) * self.emit_prob(state, genotype[0])\n",
    "\n",
    "#         return posterior, right_list\n",
    "#     def check_convergence(self,all_iters_total_likelihood,eps):\n",
    "#         if np.linalg.norm(np.array(all_iters_total_likelihood[-1]) - np.array(all_iters_total_likelihood[-2])) < eps:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     def fit(self, genotypes, max_it,eps=1e-10):\n",
    "#         pseudocount = self.pseudocount\n",
    "#         # Train by Baum-Weltch\n",
    "#         # Inititalization\n",
    "#         all_iters_KL_divergence = []\n",
    "#         transitions,emissions,initial = self.initialize_HMM_parameters_randomly(self.genotypes, self.diplotypes, self.seed)\n",
    "#         for it in range(max_it):\n",
    "#             print(f'------------------Iter:{it}------------------')\n",
    "#              # Expectation\n",
    "#             sum_Px = 0\n",
    "#             # get the sum over Px first\n",
    "#             for j in range(len(genotypes)):\n",
    "#                 genotype = genotypes[j]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, _ = self.forward(genotype)\n",
    "#     #             r_Px, r_matrix = self.backward(genotype)\n",
    "#                 sum_Px += 1/f_Px\n",
    "# #             if it >= 1 and self.check_convergence(all_iters_total_likelihood,eps):\n",
    "# #                 print(all_iters_total_likelihood)\n",
    "# #                 break\n",
    "#             for m in range(len(genotypes)):\n",
    "#                 genotype = genotypes[m]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, f_matrix = self.forward(genotype)\n",
    "#                 r_Px, r_matrix = self.backward(genotype)\n",
    "#                 for k in self.get_diplotypes():\n",
    "#                     # Update transition matrix A\n",
    "#                     for l in self.get_diplotypes():\n",
    "#                         A = 0\n",
    "#                         for i in range(len(genotype)-1):\n",
    "#                             A += f_matrix[i][k] * self.transition_prob(k,l) *  self.emit_prob(l, genotype[i+1]) * r_matrix[i+1][l]\n",
    "#                         transitions[k][l] = pseudocount + sum_Px * A\n",
    "\n",
    "#                     # Update emission matrix E\n",
    "#                     for j, sigma in enumerate(self.get_genotypes()):\n",
    "#                         E = 0\n",
    "#                         for i in range(len(genotype)):\n",
    "#                             if genotype[i] == sigma:\n",
    "#                                 E += f_matrix[i][k] * r_matrix[i][k]\n",
    "\n",
    "#                         emissions[k][sigma] = pseudocount + sum_Px * E\n",
    "\n",
    "#                     # Update initial state matrix B\n",
    "#                     initial[k] = sum_Px * f_matrix[0][k] * r_matrix[0][k] \n",
    "#              # Maximization\n",
    "#             for k in self.get_diplotypes():\n",
    "#                 sum_A = 0\n",
    "#                 for l in self.get_diplotypes():\n",
    "#                     sum_A += transitions[k][l]\n",
    "#                 for l in self.get_diplotypes():\n",
    "#                     transitions[k][l] = transitions[k][l]/sum_A\n",
    "\n",
    "\n",
    "#                 sum_E = 0\n",
    "#                 for j, sigma in enumerate(self.get_genotypes()):\n",
    "#                     sum_E += emissions[k][sigma]\n",
    "#                 for j, sigma in enumerate(self.get_genotypes()):\n",
    "#                     emissions[k][sigma] = emissions[k][sigma]/sum_E\n",
    "# #             print('Param')\n",
    "# #             print(transitions[k])\n",
    "# #             print(emissions[k])\n",
    "#             sum_B = 0\n",
    "#             for k in self.get_diplotypes():\n",
    "#                 sum_B += initial[k]\n",
    "#             for k in self.get_diplotypes():\n",
    "#                 initial[k] = initial[k]/sum_B\n",
    "# #             # Maximization\n",
    "            \n",
    "# #             for k in self.get_diplotypes():\n",
    "# #                 all_a = []\n",
    "# #                 for l in self.get_diplotypes():\n",
    "# #                     all_a.append(transitions[k][l])\n",
    "# #                 all_normalized_a = self.sum_normalize(all_a)\n",
    "# #                 for l_index,l in enumerate(self.get_diplotypes()):\n",
    "# #                     transitions[k][l] = all_normalized_a[l_index]\n",
    "                \n",
    "# #                 all_e = []\n",
    "# #                 for j, sigma in enumerate(self.get_genotypes()):\n",
    "# #                     all_e.append(emissions[k][sigma])\n",
    "                \n",
    "# #                 all_normalized_e = self.sum_normalize(all_e)\n",
    "# #                 for sigma_index, sigma in enumerate(self.get_genotypes()):\n",
    "# #                     emissions[k][sigma] = all_normalized_e[sigma_index]\n",
    "\n",
    "# #             all_b = []\n",
    "# #             for k in self.get_diplotypes():\n",
    "# #                 all_b.append(initial[k])\n",
    "# #             all_normalized_b = self.sum_normalize(all_b)\n",
    "            \n",
    "# #             for k_index,k in enumerate(self.get_diplotypes()):\n",
    "# #                 initial[k] = all_normalized_b[k_index]\n",
    "# #             if it >= 1 and self.check_convergence(transitions,eps):\n",
    "# #                 print(all_iters_total_likelihood)\n",
    "# #                 break\n",
    "#             self.transitions = transitions\n",
    "#             self.emissions = emissions\n",
    "#             self.initial = initial\n",
    "#     def predict(self, genotype):\n",
    "#         # Predict by Viterbi\n",
    "#         previous_col_probs = {} \n",
    "#         traceback = []\n",
    "#         for state in self.get_diplotypes():\n",
    "#             previous_col_probs[state] = np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n",
    "\n",
    "#         for t in range(1, len(genotype)): \n",
    "#             previous_col_probs_next = {}\n",
    "#             traceback_next = {}\n",
    "\n",
    "#             for next_state in self.get_diplotypes():  \n",
    "#                 k = {}\n",
    "#                 for this_state in self.get_diplotypes():\n",
    "#                     k[this_state] = previous_col_probs[this_state] + np.log(self.transition_prob(this_state, next_state)) \n",
    "#                 max_k = -np.inf\n",
    "#                 argmax_k = None\n",
    "#                 for state,val in k.items():\n",
    "#                     if val > max_k:\n",
    "#                         argmax_k = state\n",
    "#                         max_k = val\n",
    "#                 previous_col_probs_next[next_state] =  np.log(self.emit_prob(next_state, genotype[t])) + k[argmax_k]\n",
    "#                 traceback_next[next_state] = argmax_k\n",
    "\n",
    "#             previous_col_probs = previous_col_probs_next\n",
    "#             traceback.append(traceback_next)\n",
    "\n",
    "#         max_final_state = None\n",
    "#         max_final_prob = -np.inf\n",
    "#         for state,prob in previous_col_probs.items():\n",
    "#             if prob > max_final_prob:\n",
    "#                 max_final_prob = prob\n",
    "#                 max_final_state = state\n",
    "\n",
    "#         result = [max_final_state]\n",
    "#         for t in range(len(genotype)-2,-1,-1):\n",
    "#             result.append(traceback[t][max_final_state])\n",
    "#             max_final_state = traceback[t][max_final_state]\n",
    "\n",
    "#         return result[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5f732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "847fa2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class haplotypeHMM_fast(object):\n",
    "#     '''\n",
    "#     hidden_states -> mosaic state (X,Y), indicating states of diploids from haplotypes X and Y\n",
    "#     transition -> transition prob for mosaic state\n",
    "#     emission -> prob of genotype condition on mosaic state\n",
    "#     inital -> prob initial mosaic state\n",
    "    \n",
    "#     '''\n",
    "#     def __init__(self, alphabet, hidden_states, possible_haplotypes, seed=None):\n",
    "#         self._alphabet = alphabet\n",
    "#         self._hidden_states = hidden_states\n",
    "#         self._haplotypes = possible_haplotypes\n",
    "#         self._seed = seed\n",
    "#         self._initialize_theta()\n",
    "#         self._transitions, self._emissions, self._initial = self._initialize_HMM(self._seed)\n",
    "# #         if(self._transitions == None):\n",
    "# #             self._initialize_random(self._alphabet, self._hidden_states, self._seed)\n",
    "    \n",
    "#     def _emit(self, cur_state, symbol):\n",
    "#         return self._emissions[cur_state][symbol]\n",
    "    \n",
    "#     def _transition(self, cur_state, next_state):\n",
    "#         return self._transitions[cur_state][next_state]\n",
    "    \n",
    "#     def _init(self, cur_state):\n",
    "#         return self._initial[cur_state]\n",
    "\n",
    "#     def _states(self):\n",
    "#         for k in self._hidden_states:\n",
    "#             yield k\n",
    "#     def _emissions_by_theta(self,theta,state,prev_state):\n",
    "#         H = len(self._haplotypes)\n",
    "#         state_X,state_Y = state\n",
    "#         prev_state_X,prev_state_Y = prev_state\n",
    "#         if (state_X != prev_state_X) and (state_Y != prev_state_Y):\n",
    "#             return theta**2/H**2\n",
    "#         elif (state_X != prev_state_X) or (state_Y != prev_state_Y):\n",
    "#             return (1-theta) * theta/H + theta**2/(H**2)\n",
    "#         else:\n",
    "#             return (1-theta) ** 2+ 2*(1-theta)*theta/H + theta**2/(H**2)\n",
    "#     def _initialize_theta(self,):\n",
    "#         self._theta = np.ones(len(self._hidden_states))//100\n",
    "#     def _initialize_HMM(self,seed):\n",
    "#         transitions = {}\n",
    "#         emissions = {}\n",
    "#         initial = {}\n",
    "#         # initailize the inital prob by dirichlet distribution\n",
    "#         np.random.seed(seed=seed)\n",
    "#         initial_rand = np.random.dirichlet(np.ones(len(self._hidden_states)))\n",
    "#         for i, state in enumerate(self._states()):\n",
    "#             emissions[state] = {}\n",
    "#             transitions[state] = {}\n",
    "#             initial[state] = initial_rand\n",
    "#             E_rand = np.random.dirichlet(np.ones(len(self._alphabet)))\n",
    "#             for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                 emissions[state][sigma] = E_rand[j]\n",
    "#             for j, next_state in enumerate(self._states()):\n",
    "#                 transitions[state][next_state] = self._emissions_by_theta(self._theta[j],next_state,state)\n",
    "#         return transitions,emissions,initial\n",
    "# #     def _initialize_random(self, alphabet, states, seed):\n",
    "# #         alphabet = list(set(alphabet))\n",
    "# #         alphabet.sort()\n",
    "# #         states = list(set(states))\n",
    "# #         states.sort()\n",
    "# #         self._alphabet = alphabet\n",
    "# #         self._hidden_states = states\n",
    "\n",
    "# #         #Initialize empty matrices A and E with pseudocounts\n",
    "# #         A = {}\n",
    "# #         E = {}\n",
    "# #         I = {}\n",
    "# #         np.random.seed(seed=seed)\n",
    "# #         I_rand = np.random.dirichlet(np.ones(len(self._hidden_states)))\n",
    "# #         for i, state in enumerate(self._states()):\n",
    "# #             E[state] = {}\n",
    "# #             A[state] = {}\n",
    "# #             I[state] = I_rand[i]\n",
    "# #             E_rand = np.random.dirichlet(np.ones(len(self._alphabet)))\n",
    "# #             A_rand = np.random.dirichlet(np.ones(len(self._hidden_states)))\n",
    "# #             for j, sigma in enumerate(self._get_alphabet()):\n",
    "# #                 E[state][sigma] = E_rand[j]\n",
    "# #             for j, next_state in enumerate(self._states()):\n",
    "# #                 A[state][next_state] = A_rand[j]\n",
    "                \n",
    "# #         self._transitions = A\n",
    "# #         self._emissions = E\n",
    "# #         self._initial = I\n",
    "# #         return\n",
    "        \n",
    "#     def _get_alphabet(self):\n",
    "#         for sigma in self._alphabet:\n",
    "#             yield sigma\n",
    "\n",
    "#     def _Ca(self,hap_a,previous_left_chain,previous_geno):\n",
    "#         Ca = 0\n",
    "#         for hap_b in self._haplotypes:\n",
    "#             state = (hap_a,hap_b)\n",
    "#             Ca += previous_left_chain[state] * self._emit(state,previous_geno)\n",
    "#         return Ca\n",
    "#     def _C(self,previous_left_chain,previous_geno):\n",
    "#         C = 0\n",
    "#         for hap_a in self._haplotypes:\n",
    "#             C += self._Ca(hap_a,previous_left_chain,previous_geno)\n",
    "#         return C\n",
    "#     def forward(self, sequence):\n",
    "#         H = len(self._haplotypes)\n",
    "#         # calculate left chain prob\n",
    "#         left_list = [] \n",
    "#         left = {}\n",
    "#         for state in self._states():\n",
    "#             left[state] = 1\n",
    "#         left_list.append(left)\n",
    "\n",
    "#         for j in range(1, len(sequence)):  # For each position in the sequence\n",
    "#             left = {}\n",
    "#             for state in self._states(): # For each state\n",
    "#                 (x,y) = state\n",
    "#                 # refer to MACH paper\n",
    "#                 left[state] = left_list[j-1][state] * self._emit(state,sequence[j-1]) * (1-self._theta[j]) ** 2 + \\\n",
    "#                 self._Ca(x,left_list[j-1],sequence[j-1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._Ca(y,left_list[j-1],sequence[j-1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._C(left_list[j-1],sequence[j-1]) * self._theta[j]**2 / H**2\n",
    "\n",
    "#             left_list.append(left)\n",
    "#         Px = 0\n",
    "#         for state in self._states():\n",
    "#             Px += left_list[-1][state]\n",
    "\n",
    "#         return Px, left_list\n",
    "#     def backward(self, sequence):\n",
    "#         H = len(self._haplotypes)\n",
    "#         # calculate right chain prob\n",
    "#         right_list = [] \n",
    "#         right = {}\n",
    "#         for state in self._states():\n",
    "#             right[state] = 1\n",
    "#         right_list.append(right)\n",
    "\n",
    "#         for j in range(len(sequence)-2,-1,-1):  # For each position in the sequence\n",
    "#             right = {}\n",
    "#             for state in self._states(): # For each state\n",
    "#                 (x,y) = state\n",
    "#                 # refer to MACH paper\n",
    "#                 right[state] = right_list[0][state] * self._emit(state,sequence[j+1]) * (1-self._theta[j]) ** 2 + \\\n",
    "#                 self._Ca(x,right_list[0],sequence[j+1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._Ca(y,right_list[0],sequence[j+1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._C(right_list[0],sequence[j+1]) * self._theta[j]**2 / H**2\n",
    "\n",
    "#             right_list.insert(0,right)\n",
    "#         Px = 0\n",
    "#         for state in self._states():\n",
    "#             Px += right_list[0][state] * self._init(state) * self._emit(state, sequence[0])\n",
    "\n",
    "#         return Px, right_list\n",
    "    \n",
    "#     def baum_welch(self, sequences, pseudocount=1e-100):\n",
    "#         \"\"\" The baum-welch algorithm for unsupervised HMM parameter learning\n",
    "\n",
    "#         Args:\n",
    "#             sequence (list): a list of sequences containing valid emissions from the HMM\n",
    "#             pseudocount (float): small pseudocount value (default: 1e-100)\n",
    "\n",
    "#         Returns:\n",
    "#             None but updates the current HMM model parameters:\n",
    "#              self._transitions, self._emissions, self._initial\n",
    "        \n",
    "#         \"\"\"   \n",
    "#         # Inititalization\n",
    "#         transition,emissions,initial = self._initialize_HMM(self._seed)\n",
    "\n",
    "#         # set the max iteration to 1 here to print the first iteration\n",
    "#         max_it = 1\n",
    "#         for it in range(max_it):\n",
    "#              # Expectation\n",
    "#             sum_Px = 0\n",
    "#             # get the sum over Px first\n",
    "#             for j in range(len(sequences)):\n",
    "#                 sequence = sequences[j]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, _ = self.forward(sequence)\n",
    "#     #             r_Px, r_matrix = self.backward(sequence)\n",
    "#                 sum_Px += 1/f_Px\n",
    "#             for j in range(len(sequences)):\n",
    "#                 sequence = sequences[j]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, f_matrix = self.forward(sequence)\n",
    "#                 r_Px, r_matrix = self.backward(sequence)\n",
    "#                 for k in self._states():\n",
    "#                     # Update transition matrix A\n",
    "#                     for l in self._states():\n",
    "#                         A = 0\n",
    "#                         for i in range(len(sequence)-1):\n",
    "#                             A += f_matrix[i][k] * self._transition(k,l) *  self._emit(l, sequence[i+1]) * r_matrix[i+1][l]\n",
    "#                         transition[k][l] = sum_Px * A\n",
    "\n",
    "#                     # Update emission matrix E\n",
    "#                     for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                         E = 0\n",
    "#                         for i in range(len(sequence)):\n",
    "#                             if sequence[i] == sigma:\n",
    "#                                 E += f_matrix[i][k] * r_matrix[i][k]\n",
    "\n",
    "#                         emissions[k][sigma] = sum_Px * E\n",
    "\n",
    "#                     # Update initial state matrix B\n",
    "#                     initial[k] = sum_Px * f_matrix[0][k] * r_matrix[0][k]\n",
    "\n",
    "#             # Maximization\n",
    "#             for k in self._states():\n",
    "#                 sum_A = 0 \n",
    "#                 for l in self._states():\n",
    "#                     sum_A += transition[k][l]\n",
    "#                 for l in self._states():\n",
    "#                     transition[k][l] = transition[k][l]/sum_A\n",
    "\n",
    "\n",
    "#                 sum_E = 0\n",
    "#                 for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                     sum_E += emissions[k][sigma]\n",
    "#                 for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                     emissions[k][sigma] = emissions[k][sigma]/sum_E\n",
    "\n",
    "#             sum_B = 0\n",
    "#             for k in self._states():\n",
    "#                 sum_B += initial[k]\n",
    "#             for k in self._states():\n",
    "#                 initial[k] = initial[k]/sum_B\n",
    "\n",
    "#     #         self.__init__(self._get_alphabet, self._states, A=None, E=None, B=None, seed=None):\n",
    "#             self._transitions = transition\n",
    "#             self._emissions = emissions\n",
    "#             self._initial = initial\n",
    "# #             print(self)\n",
    "#         pass\n",
    "#     def viterbi(self, sequence):\n",
    "#         \"\"\" The viterbi algorithm for decoding a string using a HMM\n",
    "\n",
    "#         Args:\n",
    "#             sequence (list): a list of valid emissions from the HMM\n",
    "\n",
    "#         Returns:\n",
    "#             result (list): optimal path through HMM given the model parameters\n",
    "#                            using the Viterbi algorithm\n",
    "        \n",
    "#         Pseudocode for Viterbi:\n",
    "#             Initialization (=0): ()=().\n",
    "#             Recursion (=1): ()=() max((1)); \n",
    "#                                 ptr()= argmax((1)).\n",
    "#             Termination: (,)= max(()0); \n",
    "#                              = argmax(()0).\n",
    "#             Traceback: (=1): 1= ptr().\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Initialization (=0): ()=().\n",
    "#         # Initialize trellis and traceback matrices\n",
    "#         # trellis will hold the vi data as defined by Durbin et al.\n",
    "#         # and trackback will hold back pointers\n",
    "#         trellis = {} # This only needs to keep the previous column probabilities\n",
    "#         traceback = [] # This will need to hold all of the traceback data so will be an array of dicts()\n",
    "#         for state in self._states():\n",
    "#             trellis[state] = np.log10(self._init(state)) + np.log10(self._emit(state, sequence[0])) # b * e(0) for all k\n",
    "            \n",
    "#         # Next we do the recursion step:\n",
    "#         # Recursion (=1): ()=() max((1)); \n",
    "#         #                 ptr()= argmax((1)).\n",
    "#         for t in range(1, len(sequence)):  # For each position in the sequence\n",
    "#             trellis_next = {}\n",
    "#             traceback_next = {}\n",
    "\n",
    "#             for next_state in self._states():    # Calculate maxk and argmaxk\n",
    "#                 k={}\n",
    "#                 for cur_state in self._states():\n",
    "#                     k[cur_state] = trellis[cur_state] + np.log10(self._transition(cur_state, next_state)) # k(t-1) * a\n",
    "#                 argmaxk = max(k, key=k.get)\n",
    "#                 trellis_next[next_state] =  np.log10(self._emit(next_state, sequence[t])) + k[argmaxk] # k * e(t)\n",
    "#                 traceback_next[next_state] = argmaxk\n",
    "                \n",
    "#             #Overwrite trellis \n",
    "#             trellis = trellis_next\n",
    "#             #Keep trackback pointer matrix\n",
    "#             traceback.append(traceback_next)\n",
    "            \n",
    "#         # Termination: (,)= max(()0); \n",
    "#         #                  = argmax(()0).\n",
    "#         max_final_state = max(trellis, key=trellis.get)\n",
    "#         max_final_prob = trellis[max_final_state]\n",
    "                \n",
    "#         # Traceback: (=1): 1= ptr().\n",
    "#         result = [max_final_state]\n",
    "#         for t in reversed(range(len(sequence)-1)):\n",
    "#             result.append(traceback[t][max_final_state])\n",
    "#             max_final_state = traceback[t][max_final_state]\n",
    "\n",
    "#         return result[::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6434dddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2993a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "hidden_states =  list(all_possible_dips)\n",
    "alphabet = [0,1,2] # DNA Alphabet\n",
    "\n",
    "model = haplotypeHMM(alphabet, hidden_states,range(len(all_possible_haps_index)),seed=70,pseudocount=1e-100)\n",
    "\n",
    "model.fit(genos[:5,:10].T,10,eps=1e-6)\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c9f7bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [2, 0, 1, 0, 1, 1, 2, 1, 1, 2],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [2, 0, 1, 0, 1, 1, 2, 1, 1, 2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genos[:5,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acae3070",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (37,) (37,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbaum_welch_scaling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 28\u001b[0m, in \u001b[0;36mbaum_welch_scaling\u001b[0;34m(O, N, M, T, epsilon, max_iter)\u001b[0m\n\u001b[1;32m     23\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# E step\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Compute alpha using recursion\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     29\u001b[0m     alpha[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m pi \u001b[38;5;241m*\u001b[39m B[:, O[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m/\u001b[39m c[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T):\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (37,) (37,5) "
     ]
    }
   ],
   "source": [
    "baum_welch_scaling(genos[:5,:10].T,len(hidden_states),len(alphabet),len(genos[:5,:10].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011f862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haplotypeHMM [/nfs/turbo/umms-kinfai/haorli/envs/haplotypeHMM]",
   "language": "python",
   "name": "conda_haplotypehmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
