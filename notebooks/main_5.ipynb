{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f378072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da3ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_f_path = 'examples/CCDG_14151_B01_GRM_WGS_2020-08-05_chr19.filtered.shapeit2-duohmm-phased.2504.43-47Mb.ALL.maf01.haps.gz'\n",
    "sample_f_path = 'examples/CCDG_14151_B01_GRM_WGS_2020-08-05_chr19.filtered.shapeit2-duohmm-phased.2504.43-47Mb.ALL.maf01.sample.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848d2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_numSNPs = 26246\n",
    "examined_numSNPs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da961c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "start_row = random.randint(0,total_numSNPs-examined_numSNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1085dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771954de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(hap_f_path,header=None,sep=' ',skiprows=start_row,nrows=examined_numSNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403bb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure sort by position\n",
    "df = df.sort_values(by=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d42e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'training_data_{examined_numSNPs}.pkl','wb') as f:\n",
    "    pickle.dump((df,start_row,examined_numSNPs),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc55c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122d1a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5003</th>\n",
       "      <th>5004</th>\n",
       "      <th>5005</th>\n",
       "      <th>5006</th>\n",
       "      <th>5007</th>\n",
       "      <th>5008</th>\n",
       "      <th>5009</th>\n",
       "      <th>5010</th>\n",
       "      <th>5011</th>\n",
       "      <th>5012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19:45783456:A:C</td>\n",
       "      <td>45783456</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>19:45783942:C:G</td>\n",
       "      <td>45783942</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>19:45783955:T:C</td>\n",
       "      <td>45783955</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>19:45785148:G:A</td>\n",
       "      <td>45785148</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>19:45785448:A:T</td>\n",
       "      <td>45785448</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                1         2    3    4     5     6     7     8     9     \\\n",
       "0    19  19:45783456:A:C  45783456    C    A     1     0     1     1     0   \n",
       "1    19  19:45783942:C:G  45783942    G    C     1     0     1     1     0   \n",
       "2    19  19:45783955:T:C  45783955    C    T     1     1     1     1     1   \n",
       "3    19  19:45785148:G:A  45785148    A    G     1     1     1     1     1   \n",
       "4    19  19:45785448:A:T  45785448    T    A     0     0     1     1     0   \n",
       "\n",
       "   ...  5003  5004  5005  5006  5007  5008  5009  5010  5011  5012  \n",
       "0  ...     1     1     1     1     1     0     1     1     0     0  \n",
       "1  ...     0     0     1     1     0     0     1     1     0     0  \n",
       "2  ...     1     1     1     1     1     1     1     1     1     1  \n",
       "3  ...     1     1     1     1     1     1     1     1     1     1  \n",
       "4  ...     0     0     0     1     0     0     0     1     0     0  \n",
       "\n",
       "[5 rows x 5013 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340f8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "haps = df.loc[:,5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8485a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5008)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45473a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a110b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "genos = np.full(shape=(haps.shape[0],haps.shape[1]//2),fill_value=-1,dtype=int)\n",
    "## create genotypes by combining each pair of haplotypes\n",
    "for i in range(genos.shape[1]):\n",
    "    genos[:,i] = haps[:,2*i] + haps[:,2*i+1]\n",
    "genos = genos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0bec4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "class haplotypeHMM(object):\n",
    "    '''\n",
    "    hidden_states -> mosaic state (X,Y), indicating states of diploids from haplotypes X and Y\n",
    "    transition -> transition prob for mosaic state\n",
    "    emission -> prob of genotype condition on mosaic state\n",
    "    inital -> prob initial mosaic state\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, genotypes, diplotypes, possible_haplotypes,reverse_all_possible_haps_index,savedir='./checkpoints/',pseudocount=1e-100,seed=42):\n",
    "        self.genotypes = list(set(genotypes))\n",
    "        self.diplotypes = list(set(diplotypes))\n",
    "        self.haplotypes = possible_haplotypes\n",
    "        self.reverse_all_possible_haps_index = reverse_all_possible_haps_index\n",
    "        self.seed = seed\n",
    "        self.pseudocount = pseudocount\n",
    "        self.transitions,self.emissions,self.initial = self.initialize_HMM_parameters_randomly(self.genotypes, self.diplotypes, self.seed)\n",
    "        self.savedir = savedir\n",
    "    def emit_prob(self, this_state, haplotype):\n",
    "        return self.emissions[this_state][haplotype]\n",
    "    \n",
    "    def transition_prob(self, this_state, next_state):\n",
    "        return self.transitions[this_state][next_state]\n",
    "    \n",
    "    def init_prob(self, this_state):\n",
    "        return self.initial[this_state]\n",
    "\n",
    "    def get_diplotypes(self):\n",
    "        for state in self.diplotypes:\n",
    "            yield state\n",
    "    def get_genotypes(self):\n",
    "        for genotype in self.genotypes:\n",
    "            yield genotype\n",
    "    def initialize_HMM_parameters_randomly(self, alphabet, states,seed):\n",
    "        \n",
    "        transitions = {}\n",
    "        emissions = {}\n",
    "        initial = {}\n",
    "        np.random.seed(seed=seed)\n",
    "        initial_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "        for i, state in enumerate(self.get_diplotypes()):\n",
    "            transitions[state] = {}\n",
    "            emissions[state] = {}\n",
    "            initial[state] = initial_rand[i]\n",
    "            emissions_rand = np.random.dirichlet(np.ones(len(self.genotypes)))\n",
    "            transitions_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "            for j,geno in enumerate(self.get_genotypes()):\n",
    "                emissions[state][geno] = emissions_rand[j]\n",
    "            for j, next_state in enumerate(self.get_diplotypes()):\n",
    "                transitions[state][next_state] = transitions_rand[j]\n",
    "                \n",
    "        return transitions,emissions,initial\n",
    "#     def initialize_HMM_parameters_MACH(self, alphabet, states,seed):\n",
    "#         theta = epsi = 0.01\n",
    "#         H = len(self.haplotypes)\n",
    "#         transitions = {}\n",
    "#         emissions = {}\n",
    "#         initial = {}\n",
    "#         np.random.seed(seed=seed)\n",
    "#         initial_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "#         for i, state in enumerate(self.get_diplotypes()):\n",
    "#             transitions[state] = {}\n",
    "#             emissions[state] = {}\n",
    "#             initial[state] = initial_rand[i]\n",
    "#             # update emission matrix\n",
    "#             for j,geno in enumerate(self.get_genotypes()):\n",
    "#                 if geno ==1:\n",
    "#                     emissions[state][geno] = emissions_rand[j]\n",
    "                \n",
    "#             # update transition matrix\n",
    "#             state_x, state_y = state\n",
    "#             for j, next_state in enumerate(self.get_diplotypes()):\n",
    "#                 next_state_x,next_state_y = next_state\n",
    "#                 if (state_X != next_state_x) and (state_Y != next_state_y):\n",
    "#                     transitions[state][next_state] =  theta**2/H**2\n",
    "#                 elif (state_X != next_state_x) or (state_Y != next_state_y):\n",
    "#                     transitions[state][next_state] =  (1-theta) * theta/H + theta**2/(H**2)\n",
    "#                 else:\n",
    "#                     transitions[state][next_state] =  (1-theta) ** 2+ 2*(1-theta)*theta/H + theta**2/(H**2)\n",
    "#         return transitions,emissions,initial\n",
    "    def logsumexp(self,lst):\n",
    "        arr = np.array(lst)\n",
    "#         log_arr =np.log(arr)\n",
    "#         if np.any(arr<=0):\n",
    "#             print(arr)\n",
    "#             raise Exception()\n",
    "        return logsumexp(arr)\n",
    "    def forward(self, genotype):\n",
    "        log_left_list = []\n",
    "        log_left = {}\n",
    "        for state in self.get_diplotypes():\n",
    "            log_left[state] = np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n",
    "        log_left_list.append(log_left)\n",
    "        for i in range(1, len(genotype)):\n",
    "            log_left = {}\n",
    "            for next_state in self.get_diplotypes(): \n",
    "                log_left[next_state] = 0\n",
    "                temp_log_left =[]\n",
    "                for this_state in self.get_diplotypes():\n",
    "                    state_log_left = log_left_list[i-1][this_state] + np.log(self.transition_prob(this_state, next_state)) + np.log(self.emit_prob(next_state, genotype[i]))\n",
    "                    assert state_log_left < 0\n",
    "                    temp_log_left.append(state_log_left)\n",
    "                log_left[next_state] =  self.logsumexp(temp_log_left)\n",
    "            log_left_list.append(log_left)\n",
    "#         posterior = 0\n",
    "#         print(log_left_list)\n",
    "        temp_log_left = []\n",
    "        for state in self.get_diplotypes():\n",
    "            assert log_left_list[-1][state] < 0\n",
    "            temp_log_left.append(log_left_list[-1][state])\n",
    "#             posterior += left_list[-1][state]\n",
    "        posterior = self.logsumexp(temp_log_left)\n",
    "        return posterior, log_left_list\n",
    "\n",
    "\n",
    "    def backward(self, genotype):\n",
    "        log_right_list = [] \n",
    "        log_right = {}\n",
    "        for state in self.get_diplotypes():\n",
    "            log_right[state] = 0\n",
    "        log_right_list.append(log_right)\n",
    "\n",
    "        for i in range(len(genotype)-1, 0, -1):\n",
    "            log_right = {} \n",
    "            for state in self.get_diplotypes():\n",
    "                temp_log_right = []\n",
    "                for next_state in self.get_diplotypes():\n",
    "                    state_log_right = log_right_list[0][next_state] + np.log(self.transition_prob(state, next_state)) + np.log(self.emit_prob(next_state, genotype[i]))\n",
    "                    assert state_log_right < 0\n",
    "                    temp_log_right.append(state_log_right)\n",
    "                log_right[state] = self.logsumexp(temp_log_right)\n",
    "            log_right_list.insert(0,log_right)\n",
    "        \n",
    "#         right_list = []\n",
    "#         for log_right in log_right_list:\n",
    "#             for this_state in self.get_diplotypes():\n",
    "#                 log_right[this_state] = np.exp(log_right[this_state])\n",
    "#             right_list.append(log_right)\n",
    "#         posterior = 0\n",
    "        temp_log_right = []\n",
    "        for state in self.get_diplotypes():\n",
    "            state_log_posterior = log_right_list[0][state] + np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n",
    "            assert state_log_posterior<0\n",
    "            temp_log_right.append(state_log_posterior)\n",
    "        posterior =  self.logsumexp(temp_log_right)\n",
    "\n",
    "        return posterior, log_right_list\n",
    "    \n",
    "    def check_convergence(self,this_px,previous_px,eps):\n",
    "        if np.linalg.norm(np.array(this_px) - np.array(previous_px))/np.linalg.norm(np.array(previous_px)) < eps:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def fit(self,genotypes,max_it,eps,choice='Baum-Welch'):\n",
    "        if choice == 'Baum-Welch':\n",
    "            self.fit_Baum_Welch(genotypes,max_it,eps)\n",
    "    \n",
    "    def fit_Baum_Welch(self, genotypes, max_it,eps):\n",
    "        # Train by Baum-Welch\n",
    "        # Inititalization\n",
    "        # store the previous complete likelihood of data\n",
    "        previous_px = []\n",
    "        for it in range(max_it):\n",
    "            # intialize the temp parameters we use for this iteration\n",
    "            transitions = {}\n",
    "            emissions = {}\n",
    "            initial = {}\n",
    "            for k in self.get_diplotypes():\n",
    "                transitions[k] = {}\n",
    "                emissions[k] = {}\n",
    "                initial[k] = []\n",
    "                for l in self.get_diplotypes():\n",
    "                    transitions[k][l] = []\n",
    "                for m in self.get_genotypes():\n",
    "                    emissions[k][m] = []\n",
    "            # to store the complete likelihood of each sample\n",
    "            this_px = []\n",
    "            for genotype in genotypes:\n",
    "                # forward and backward\n",
    "                log_f_Px, log_f_matrix = self.forward(genotype)\n",
    "                log_r_Px, log_r_matrix = self.backward(genotype)\n",
    "                # store the complete likelihood of each sample. log_f_Px == log_r_Px with allowed marginal mismatch \n",
    "                this_px.append(log_f_Px)\n",
    "                for k in self.get_diplotypes():\n",
    "                    # Update transition matrix A\n",
    "                    for l in self.get_diplotypes():\n",
    "                        all_A = []\n",
    "                        for i in range(len(genotype)-1):\n",
    "                            all_A.append(log_f_matrix[i][k] + np.log(self.transition_prob(k,l)) + np.log(self.emit_prob(l, genotype[i+1])) + log_r_matrix[i+1][l])                            \n",
    "                        transitions[k][l].append(-log_f_Px+ self.logsumexp(all_A))\n",
    "\n",
    "                    # Update emission matrix E\n",
    "                    for j, sigma in enumerate(self.get_genotypes()):\n",
    "                        all_E = []\n",
    "                        for i in range(len(genotype)):\n",
    "                            if genotype[i] == sigma:\n",
    "                                all_E.append(log_f_matrix[i][k] + log_r_matrix[i][k])\n",
    "                        if len(all_E) != 0:\n",
    "                            emissions[k][sigma].append(-log_f_Px +self.logsumexp(all_E))\n",
    "\n",
    "                    # Update initial state matrix B\n",
    "                    initial[k].append(-log_f_Px + log_f_matrix[0][k] + log_r_matrix[0][k])\n",
    "            # Maximization\n",
    "            for k in self.get_diplotypes():\n",
    "                initial[k] = np.exp(self.logsumexp(initial[k]))\n",
    "                for l in self.get_diplotypes():\n",
    "                    transitions[k][l] = np.exp(self.logsumexp(transitions[k][l]))\n",
    "                for m in self.get_genotypes():\n",
    "                    emissions[k][m] = np.exp(self.logsumexp(emissions[k][m]))\n",
    "                    \n",
    "                    \n",
    "                \n",
    "            for k in self.get_diplotypes():\n",
    "                sum_A = 0\n",
    "                for l in self.get_diplotypes():\n",
    "                    sum_A += transitions[k][l]\n",
    "                for l in self.get_diplotypes():\n",
    "                    transitions[k][l] = transitions[k][l]/sum_A\n",
    "\n",
    "\n",
    "                sum_E = 0\n",
    "                for j, sigma in enumerate(self.get_genotypes()):\n",
    "                    sum_E += emissions[k][sigma]\n",
    "                for j, sigma in enumerate(self.get_genotypes()):\n",
    "                    emissions[k][sigma] = emissions[k][sigma]/sum_E\n",
    "\n",
    "            sum_B = 0\n",
    "            for k in self.get_diplotypes():\n",
    "                sum_B += initial[k]\n",
    "            for k in self.get_diplotypes():\n",
    "                initial[k] = initial[k]/sum_B\n",
    "            self.transitions = transitions\n",
    "            self.emissions = emissions\n",
    "            self.initial = initial\n",
    "            self.save_checkpoint(self.savedir,it)\n",
    "            # Check covergence\n",
    "            if it > 0 and self.check_convergence(this_px,previous_px,eps):\n",
    "                break\n",
    "            previous_px = this_px\n",
    "            with open(self.savedir+'/log.txt','a+') as fout:\n",
    "                fout.write(f'Iteration:{it}:\\n')\n",
    "                fout.write(f'Average complete log likelihoods:{it}:\\n')\n",
    "                fout.write(str(np.mean(this_px))+'\\n')\n",
    "            print(f'Iteration:{it}:')\n",
    "#             print(this_px)\n",
    "            print(f'Average complete log likelihoods:')\n",
    "            print(np.mean(this_px))\n",
    "#     def fit_Viterbi(self, genotypes, max_it,eps):\n",
    "        \n",
    "    def check_compatible_with_genotype(self,genotype,hap_1,hap_2):\n",
    "        assert len(hap_1) == len(hap_2) == len(genotype) \n",
    "        incompatible_snps = 0\n",
    "        for i in range(len(genotype)):\n",
    "            if  hap_1[i] + hap_2[i] != genotype[i]:\n",
    "                incompatible_snps += 1\n",
    "        return incompatible_snps\n",
    "    def predict(self,genotypes,choice='Viterbi'):\n",
    "        predictions = []\n",
    "        for genotype in genotypes:\n",
    "            if choice == 'Viterbi':\n",
    "                haplotype_pairs = self.predict_Viterbi(genotype)\n",
    "                haplotypes_incompatibility = {}\n",
    "                min_incompatibility = len(genotype) + 1\n",
    "                valid_haplotypes = []\n",
    "                valid_haplotypes_genotypes = []\n",
    "                for haplotype_pair,geno in zip(haplotype_pairs,genotype):\n",
    "                    hap_1 = self.reverse_all_possible_haps_index[haplotype_pair[0]]\n",
    "                    hap_2 = self.reverse_all_possible_haps_index[haplotype_pair[1]]\n",
    "                    incompatibility = self.check_compatible_with_genotype(genotype,hap_1,hap_2)\n",
    "                    if incompatibility < min_incompatibility:\n",
    "                        valid_haplotypes = []\n",
    "                        valid_haplotypes_genotypes = []\n",
    "                        valid_haplotypes.append(haplotype_pair)\n",
    "                        valid_haplotypes_genotypes.append(geno)\n",
    "                    elif incompatibility == min_incompatibility:\n",
    "                        valid_haplotypes.append(haplotype_pair)\n",
    "                        valid_haplotypes_genotypes.append(geno)\n",
    "                if len(valid_haplotypes) == 1:\n",
    "                    best_haplotype_pair = valid_haplotypes[0]\n",
    "                elif len(valid_haplotypes) > 1:\n",
    "                    probs = [self.emit_prob(state,geno) for (state,geno) in zip(valid_haplotypes,valid_haplotypes_genotypes)]\n",
    "                    best_haplotype_pair = valid_haplotypes[np.argmax(probs)]\n",
    "                else:\n",
    "                    best_haplotype_pair = None\n",
    "                if best_haplotype_pair:\n",
    "                    hap_1 = self.reverse_all_possible_haps_index[best_haplotype_pair[0]]\n",
    "                    hap_2 = self.reverse_all_possible_haps_index[best_haplotype_pair[1]]\n",
    "                    predictions.append(np.array([hap_1,hap_2]))\n",
    "        return np.array(predictions)\n",
    "#     def predict_from_emission(self,genotype):\n",
    "#         max_prob = 0\n",
    "#         most_likely_haplotype = None\n",
    "#         for i in range(len(genotype)):\n",
    "#             for state in self.get_diplotypes():\n",
    "#                 if self.emit_prob(state,genotype[i]) > max_prob:\n",
    "#                     max_prob = self.emit_prob(state,genotype[i])\n",
    "#                     most_likely_haplotype = state\n",
    "#         return most_likely_haplotype\n",
    "    def save_checkpoint(self,check_point_folder,it):\n",
    "        Path(check_point_folder).mkdir(exist_ok=True,parents=True)\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        with open(check_point_folder+f'/{it}_{timestr}.pt','wb') as f:\n",
    "            pickle.dump(self,f)\n",
    "    def predict_Viterbi(self, genotype):\n",
    "        # Predict by Viterbi\n",
    "        previous_col_probs = {} \n",
    "        traceback = []\n",
    "        for state in self.get_diplotypes():\n",
    "            previous_col_probs[state] = np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n",
    "\n",
    "        for t in range(1, len(genotype)): \n",
    "            previous_col_probs_next = {}\n",
    "            traceback_next = {}\n",
    "\n",
    "            for next_state in self.get_diplotypes():  \n",
    "                k = {}\n",
    "                for this_state in self.get_diplotypes():\n",
    "                    k[this_state] = previous_col_probs[this_state] + np.log(self.transition_prob(this_state, next_state)) \n",
    "                max_k = -np.inf\n",
    "                argmax_k = None\n",
    "                for state,val in k.items():\n",
    "                    if val > max_k:\n",
    "                        argmax_k = state\n",
    "                        max_k = val\n",
    "                previous_col_probs_next[next_state] =  np.log(self.emit_prob(next_state, genotype[t])) + k[argmax_k]\n",
    "                traceback_next[next_state] = argmax_k\n",
    "\n",
    "            previous_col_probs = previous_col_probs_next\n",
    "            traceback.append(traceback_next)\n",
    "\n",
    "        max_final_state = None\n",
    "        max_final_prob = -np.inf\n",
    "        for state,prob in previous_col_probs.items():\n",
    "            if prob > max_final_prob:\n",
    "                max_final_prob = prob\n",
    "                max_final_state = state\n",
    "\n",
    "        result = [max_final_state]\n",
    "        for t in range(len(genotype)-2,-1,-1):\n",
    "            result.append(traceback[t][max_final_state])\n",
    "            max_final_state = traceback[t][max_final_state]\n",
    "\n",
    "        return result[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92fb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_possible_haps(genotypes):\n",
    "    all_possible_haps_index = {}\n",
    "    all_possible_dips = []\n",
    "    num_samples,num_SNPs = genotypes.shape\n",
    "    for i in range(num_samples):\n",
    "        this_sample_possible_haps = [()]\n",
    "        for j in range(num_SNPs):\n",
    "            if genotypes[i,j] == 2:\n",
    "                for k in range(len(this_sample_possible_haps)):\n",
    "                    this_sample_possible_haps[k]+=(1,)\n",
    "            elif genotypes[i,j] == 0:\n",
    "                for k in range(len(this_sample_possible_haps)):\n",
    "                    this_sample_possible_haps[k]+=(0,)\n",
    "            else:\n",
    "                new_this_sample_possible_haps = []\n",
    "                previous_all_haps = this_sample_possible_haps.copy()\n",
    "                for k in range(len(previous_all_haps)):\n",
    "                    previous_all_haps[k]+=(1,)\n",
    "                new_this_sample_possible_haps += previous_all_haps\n",
    "                previous_all_haps = this_sample_possible_haps.copy()\n",
    "                for k in range(len(previous_all_haps)):\n",
    "                    previous_all_haps[k]+=(0,)\n",
    "                new_this_sample_possible_haps += previous_all_haps\n",
    "                this_sample_possible_haps = new_this_sample_possible_haps\n",
    "        if len(this_sample_possible_haps) == 1:\n",
    "            hap = this_sample_possible_haps[0]\n",
    "            if hap not in all_possible_haps_index:\n",
    "                all_possible_haps_index[hap] = len(all_possible_haps_index)\n",
    "            all_possible_dips.append((all_possible_haps_index[hap],all_possible_haps_index[hap]))\n",
    "        else:\n",
    "            for l in range(len(this_sample_possible_haps)//2):\n",
    "                hap_1 = this_sample_possible_haps[l] \n",
    "                hap_2 = this_sample_possible_haps[len(this_sample_possible_haps)-l-1] \n",
    "                if hap_1 not in all_possible_haps_index:\n",
    "                    all_possible_haps_index[hap_1] = len(all_possible_haps_index)\n",
    "                if hap_2 not in all_possible_haps_index:\n",
    "                    all_possible_haps_index[hap_2] = len(all_possible_haps_index)\n",
    "                if all_possible_haps_index[hap_1]<= all_possible_haps_index[hap_2]:\n",
    "                    all_possible_dips.append((all_possible_haps_index[hap_1],all_possible_haps_index[hap_2]))\n",
    "                else:\n",
    "                    all_possible_dips.append((all_possible_haps_index[hap_2],all_possible_haps_index[hap_1]))\n",
    "    all_possible_dips = set(all_possible_dips)\n",
    "    reverse_all_possible_haps_index = {}\n",
    "    for hap,index in all_possible_haps_index.items():\n",
    "        reverse_all_possible_haps_index[index] = hap\n",
    "    return all_possible_haps_index,all_possible_dips,reverse_all_possible_haps_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "546e21da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0:\n",
      "Average complete log likelihoods:\n",
      "-5.455329224097556\n",
      "Iteration:1:\n",
      "Average complete log likelihoods:\n",
      "-4.875452615496234\n",
      "Iteration:2:\n",
      "Average complete log likelihoods:\n",
      "-4.793940067902931\n",
      "Iteration:3:\n",
      "Average complete log likelihoods:\n",
      "-4.707290730428977\n",
      "Iteration:4:\n",
      "Average complete log likelihoods:\n",
      "-4.59896504617421\n",
      "Iteration:5:\n",
      "Average complete log likelihoods:\n",
      "-4.446856829575462\n",
      "Iteration:6:\n",
      "Average complete log likelihoods:\n",
      "-4.2254593261048505\n",
      "Iteration:7:\n",
      "Average complete log likelihoods:\n",
      "-3.9322690963724622\n",
      "Iteration:8:\n",
      "Average complete log likelihoods:\n",
      "-3.6081038588517456\n",
      "Iteration:9:\n",
      "Average complete log likelihoods:\n",
      "-3.29663601499735\n",
      "Iteration:10:\n",
      "Average complete log likelihoods:\n",
      "-3.0111088391225302\n",
      "Iteration:11:\n",
      "Average complete log likelihoods:\n",
      "-2.747456979789941\n",
      "Iteration:12:\n",
      "Average complete log likelihoods:\n",
      "-2.5576750404653197\n",
      "Iteration:13:\n",
      "Average complete log likelihoods:\n",
      "-2.4674823046930046\n",
      "Iteration:14:\n",
      "Average complete log likelihoods:\n",
      "-2.4280461072063586\n",
      "Iteration:15:\n",
      "Average complete log likelihoods:\n",
      "-2.4090697011576574\n",
      "Iteration:16:\n",
      "Average complete log likelihoods:\n",
      "-2.3984194800974783\n",
      "Iteration:17:\n",
      "Average complete log likelihoods:\n",
      "-2.3914146327712205\n",
      "Iteration:18:\n",
      "Average complete log likelihoods:\n",
      "-2.3861975546090908\n",
      "Iteration:19:\n",
      "Average complete log likelihoods:\n",
      "-2.3821416754894873\n",
      "Iteration:20:\n",
      "Average complete log likelihoods:\n",
      "-2.3790429768385057\n",
      "Iteration:21:\n",
      "Average complete log likelihoods:\n",
      "-2.3766270190605776\n",
      "Iteration:22:\n",
      "Average complete log likelihoods:\n",
      "-2.374661039221577\n",
      "Iteration:23:\n",
      "Average complete log likelihoods:\n",
      "-2.3729897000769493\n",
      "Iteration:24:\n",
      "Average complete log likelihoods:\n",
      "-2.3714983555754032\n",
      "Iteration:25:\n",
      "Average complete log likelihoods:\n",
      "-2.3700909205440874\n",
      "Iteration:26:\n",
      "Average complete log likelihoods:\n",
      "-2.3686796505843444\n",
      "Iteration:27:\n",
      "Average complete log likelihoods:\n",
      "-2.3671794367951535\n",
      "Iteration:28:\n",
      "Average complete log likelihoods:\n",
      "-2.36550383716984\n",
      "Iteration:29:\n",
      "Average complete log likelihoods:\n",
      "-2.3635626910255025\n",
      "Iteration:30:\n",
      "Average complete log likelihoods:\n",
      "-2.3612628401989277\n",
      "Iteration:31:\n",
      "Average complete log likelihoods:\n",
      "-2.3585147765372643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_922250/2333178164.py:95: RuntimeWarning: divide by zero encountered in log\n",
      "  log_left[state] = np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n",
      "/tmp/ipykernel_922250/2333178164.py:145: RuntimeWarning: divide by zero encountered in log\n",
      "  state_log_posterior = log_right_list[0][state] + np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:32:\n",
      "Average complete log likelihoods:\n",
      "-2.3552485058689467\n",
      "Iteration:33:\n",
      "Average complete log likelihoods:\n",
      "-2.3514399081390143\n",
      "Iteration:34:\n",
      "Average complete log likelihoods:\n",
      "-2.347142254899869\n",
      "Iteration:35:\n",
      "Average complete log likelihoods:\n",
      "-2.342507233910895\n",
      "Iteration:36:\n",
      "Average complete log likelihoods:\n",
      "-2.3377744916608534\n",
      "Iteration:37:\n",
      "Average complete log likelihoods:\n",
      "-2.3332209482794135\n",
      "Iteration:38:\n",
      "Average complete log likelihoods:\n",
      "-2.3290891504686018\n",
      "Iteration:39:\n",
      "Average complete log likelihoods:\n",
      "-2.3255321334396304\n",
      "Iteration:40:\n",
      "Average complete log likelihoods:\n",
      "-2.322599452776826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "training_data = genos[:,:]\n",
    "possible_genotypes = [0,1,2]\n",
    "all_possible_haps_index,all_possible_dips,reverse_all_possible_haps_index = construct_possible_haps(training_data)\n",
    "model = haplotypeHMM(possible_genotypes, list(all_possible_dips),range(len(all_possible_haps_index)),reverse_all_possible_haps_index,savedir='./5_SNPs/',seed=70,pseudocount=1e-100)\n",
    "\n",
    "model.fit(training_data,100,1e-3)\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89df67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '''Iteration:0:\n",
    "Average complete log likelihoods:\n",
    "-5.455329224097556\n",
    "Iteration:1:\n",
    "Average complete log likelihoods:\n",
    "-4.875452615496234\n",
    "Iteration:2:\n",
    "Average complete log likelihoods:\n",
    "-4.793940067902931\n",
    "Iteration:3:\n",
    "Average complete log likelihoods:\n",
    "-4.707290730428977\n",
    "Iteration:4:\n",
    "Average complete log likelihoods:\n",
    "-4.59896504617421\n",
    "Iteration:5:\n",
    "Average complete log likelihoods:\n",
    "-4.446856829575462\n",
    "Iteration:6:\n",
    "Average complete log likelihoods:\n",
    "-4.2254593261048505\n",
    "Iteration:7:\n",
    "Average complete log likelihoods:\n",
    "-3.9322690963724622\n",
    "Iteration:8:\n",
    "Average complete log likelihoods:\n",
    "-3.6081038588517456\n",
    "Iteration:9:\n",
    "Average complete log likelihoods:\n",
    "-3.29663601499735\n",
    "Iteration:10:\n",
    "Average complete log likelihoods:\n",
    "-3.0111088391225302\n",
    "Iteration:11:\n",
    "Average complete log likelihoods:\n",
    "-2.747456979789941\n",
    "Iteration:12:\n",
    "Average complete log likelihoods:\n",
    "-2.5576750404653197\n",
    "Iteration:13:\n",
    "Average complete log likelihoods:\n",
    "-2.4674823046930046\n",
    "Iteration:14:\n",
    "Average complete log likelihoods:\n",
    "-2.4280461072063586\n",
    "Iteration:15:\n",
    "Average complete log likelihoods:\n",
    "-2.4090697011576574\n",
    "Iteration:16:\n",
    "Average complete log likelihoods:\n",
    "-2.3984194800974783\n",
    "Iteration:17:\n",
    "Average complete log likelihoods:\n",
    "-2.3914146327712205\n",
    "Iteration:18:\n",
    "Average complete log likelihoods:\n",
    "-2.3861975546090908\n",
    "Iteration:19:\n",
    "Average complete log likelihoods:\n",
    "-2.3821416754894873\n",
    "Iteration:20:\n",
    "Average complete log likelihoods:\n",
    "-2.3790429768385057\n",
    "Iteration:21:\n",
    "Average complete log likelihoods:\n",
    "-2.3766270190605776\n",
    "Iteration:22:\n",
    "Average complete log likelihoods:\n",
    "-2.374661039221577\n",
    "Iteration:23:\n",
    "Average complete log likelihoods:\n",
    "-2.3729897000769493\n",
    "Iteration:24:\n",
    "Average complete log likelihoods:\n",
    "-2.3714983555754032\n",
    "Iteration:25:\n",
    "Average complete log likelihoods:\n",
    "-2.3700909205440874\n",
    "Iteration:26:\n",
    "Average complete log likelihoods:\n",
    "-2.3686796505843444\n",
    "Iteration:27:\n",
    "Average complete log likelihoods:\n",
    "-2.3671794367951535\n",
    "Iteration:28:\n",
    "Average complete log likelihoods:\n",
    "-2.36550383716984\n",
    "Iteration:29:\n",
    "Average complete log likelihoods:\n",
    "-2.3635626910255025\n",
    "Iteration:30:\n",
    "Average complete log likelihoods:\n",
    "-2.3612628401989277\n",
    "Iteration:31:\n",
    "Average complete log likelihoods:\n",
    "-2.3585147765372643\n",
    "Iteration:32:\n",
    "Average complete log likelihoods:\n",
    "-2.3552485058689467\n",
    "Iteration:33:\n",
    "Average complete log likelihoods:\n",
    "-2.3514399081390143\n",
    "Iteration:34:\n",
    "Average complete log likelihoods:\n",
    "-2.347142254899869\n",
    "Iteration:35:\n",
    "Average complete log likelihoods:\n",
    "-2.342507233910895\n",
    "Iteration:36:\n",
    "Average complete log likelihoods:\n",
    "-2.3377744916608534\n",
    "Iteration:37:\n",
    "Average complete log likelihoods:\n",
    "-2.3332209482794135\n",
    "Iteration:38:\n",
    "Average complete log likelihoods:\n",
    "-2.3290891504686018\n",
    "Iteration:39:\n",
    "Average complete log likelihoods:\n",
    "-2.3255321334396304\n",
    "Iteration:40:\n",
    "Average complete log likelihoods:\n",
    "-2.322599452776826'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9b4b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = []\n",
    "for line in output.split('\\n')[2::3]:\n",
    "    log_likelihood.append(float(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576e21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884ebf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = [-5.455329224097556,\n",
    " -4.875452615496234,\n",
    " -4.793940067902931,\n",
    " -4.707290730428977,\n",
    " -4.59896504617421,\n",
    " -4.446856829575462,\n",
    " -4.2254593261048505,\n",
    " -3.9322690963724622,\n",
    " -3.6081038588517456,\n",
    " -3.29663601499735,\n",
    " -3.0111088391225302,\n",
    " -2.747456979789941,\n",
    " -2.5576750404653197,\n",
    " -2.4674823046930046,\n",
    " -2.4280461072063586,\n",
    " -2.4090697011576574,\n",
    " -2.3984194800974783,\n",
    " -2.3914146327712205,\n",
    " -2.3861975546090908,\n",
    " -2.3821416754894873,\n",
    " -2.3790429768385057,\n",
    " -2.3766270190605776,\n",
    " -2.374661039221577,\n",
    " -2.3729897000769493,\n",
    " -2.3714983555754032,\n",
    " -2.3700909205440874,\n",
    " -2.3686796505843444,\n",
    " -2.3671794367951535,\n",
    " -2.36550383716984,\n",
    " -2.3635626910255025,\n",
    " -2.3612628401989277,\n",
    " -2.3585147765372643,\n",
    " -2.3552485058689467,\n",
    " -2.3514399081390143,\n",
    " -2.347142254899869,\n",
    " -2.342507233910895,\n",
    " -2.3377744916608534,\n",
    " -2.3332209482794135,\n",
    " -2.3290891504686018,\n",
    " -2.3255321334396304,\n",
    " -2.322599452776826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "257e7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b1a8439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_likelihood)\n",
    "plt.ylabel('Log data likelihood')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea10d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8051.939712047577\n"
     ]
    }
   ],
   "source": [
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a07ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(training_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a24af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class haplotypeHMM(object):\n",
    "#     '''\n",
    "#     hidden_states -> mosaic state (X,Y), indicating states of diploids from haplotypes X and Y\n",
    "#     transition -> transition prob for mosaic state\n",
    "#     emission -> prob of genotype condition on mosaic state\n",
    "#     inital -> prob initial mosaic state\n",
    "    \n",
    "#     '''\n",
    "#     def __init__(self, genotypes, diplotypes, possible_haplotypes,seed=42,pseudocount=1e-100):\n",
    "#         self.genotypes = list(set(genotypes))\n",
    "#         self.diplotypes = list(set(hidden_states))\n",
    "#         self.haplotypes = possible_haplotypes\n",
    "#         self.seed = seed\n",
    "#         self.pseudocount = pseudocount\n",
    "#         self.transitions,self.emissions,self.initial = self.initialize_HMM_parameters_randomly(self.genotypes, self.diplotypes, self.seed)\n",
    "    \n",
    "#     def emit_prob(self, this_state, haplotype):\n",
    "#         return self.emissions[this_state][haplotype]\n",
    "    \n",
    "#     def transition_prob(self, this_state, next_state):\n",
    "#         return self.transitions[this_state][next_state]\n",
    "    \n",
    "#     def init_prob(self, this_state):\n",
    "#         return self.initial[this_state]\n",
    "\n",
    "#     def get_diplotypes(self):\n",
    "#         for state in self.diplotypes:\n",
    "#             yield state\n",
    "#     def get_genotypes(self):\n",
    "#         for genotype in self.genotypes:\n",
    "#             yield genotype\n",
    "#     def initialize_HMM_parameters_randomly(self, alphabet, states,seed):\n",
    "        \n",
    "#         transitions = {}\n",
    "#         emissions = {}\n",
    "#         initial = {}\n",
    "#         np.random.seed(seed=seed)\n",
    "#         initial_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "#         for i, state in enumerate(self.get_diplotypes()):\n",
    "#             transitions[state] = {}\n",
    "#             emissions[state] = {}\n",
    "#             initial[state] = initial_rand[i]\n",
    "#             emissions_rand = np.random.dirichlet(np.ones(len(self.genotypes)))\n",
    "#             transitions_rand = np.random.dirichlet(np.ones(len(self.diplotypes)))\n",
    "#             for j,geno in enumerate(self.get_genotypes()):\n",
    "#                 emissions[state][geno] = emissions_rand[j]\n",
    "#             for j, next_state in enumerate(self.get_diplotypes()):\n",
    "#                 transitions[state][next_state] = transitions_rand[j]\n",
    "                \n",
    "#         return transitions,emissions,initial\n",
    "#     def log_sum_exp(self,x):\n",
    "#         x_arr = np.array(x)\n",
    "#         x_log_arr = np.log(x_arr)\n",
    "#         x_log_max = x_log_arr.max()\n",
    "#         return x_log_max + np.log(np.sum(np.e**(x_log_arr-x_log_max)))\n",
    "#     def sum_normalize(self,x):\n",
    "#         return np.exp(np.log(np.array(x))-self.log_sum_exp(x))\n",
    "#     def calculate_s_value(self, seq_pos, previous_vars,single_pos_genotype):\n",
    "#         \"\"\"Calculate the next scaling variable for a sequence position (PRIVATE).\n",
    "#         This utilizes the approach of choosing s values such that the\n",
    "#         sum of all of the scaled f values is equal to 1.\n",
    "#         Arguments:\n",
    "#          - seq_pos -- The current position we are at in the sequence.\n",
    "#          - previous_vars -- All of the forward or backward variables\n",
    "#            calculated so far.\n",
    "#         Returns:\n",
    "#          - The calculated scaling variable for the sequence item.\n",
    "#         \"\"\"\n",
    "#         # all of the different letters the state can have\n",
    "#         state_letters = self.get_diplotypes()\n",
    "\n",
    "#         # loop over all of the possible states\n",
    "#         s_value = 0\n",
    "#         for main_state in state_letters:\n",
    "#             emission = self.emit_prob(main_state,single_pos_genotype)\n",
    "\n",
    "#             # now sum over all of the previous vars and transitions\n",
    "#             trans_and_var_sum = 0\n",
    "#             for second_state in state_letters:\n",
    "#                 # the value of the previous f or b value\n",
    "#                 var_value = previous_vars[seq_pos - 1][second_state]\n",
    "\n",
    "#                 # the transition probability\n",
    "#                 trans_value = self.transition_prob(main_state,second_state)\n",
    "\n",
    "#                 trans_and_var_sum += var_value * trans_value\n",
    "\n",
    "#             s_value += emission * trans_and_var_sum\n",
    "\n",
    "#         return s_value\n",
    "#     def forward(self, genotype):\n",
    "#         left_list = []\n",
    "#         left = {}\n",
    "#         for state in self.get_diplotypes():\n",
    "#             left[state] = self.init_prob(state) * self.emit_prob(state, genotype[0])\n",
    "#         left_list.append(left)\n",
    "        \n",
    "#         for i in range(1, len(genotype)):\n",
    "#             s_value = self.calculate_s_value(i,left_list,genotype[i])\n",
    "#             left = {}\n",
    "#             for next_state in self.get_diplotypes(): \n",
    "#                 left[next_state] = 0\n",
    "#                 for this_state in self.get_diplotypes():\n",
    "#                     left[next_state] += left_list[i-1][this_state] * self.transition_prob(this_state, next_state) \n",
    "#                 left[next_state] =  self.emit_prob(next_state, genotype[i]) * left[next_state]\n",
    "#             for next_state in self.get_diplotypes():\n",
    "#                 left[next_state] /= s_value\n",
    "#             left_list.append(left)\n",
    "#         # rescale left\n",
    "# #         print('LEFT')\n",
    "# #         print(left_list)\n",
    "# #         print(scale_list)\n",
    "# #         for i in range(len(left_list)):\n",
    "# #             for state in self.get_diplotypes():\n",
    "# #                 left_list[i][state] *= np.sum(scale_list[:i+1])\n",
    "#         posterior = 0\n",
    "#         for state in self.get_diplotypes():\n",
    "#             posterior += left_list[-1][state]\n",
    "\n",
    "#         return posterior, left_list\n",
    "\n",
    "\n",
    "#     def backward(self, genotype):\n",
    "# #         scale_list = [1]\n",
    "#         right_list = [] \n",
    "#         right = {}\n",
    "#         for state in self.get_diplotypes():\n",
    "#             right[state] = 1\n",
    "#         right_list.append(right)\n",
    "\n",
    "#         for i in range(len(genotype)-2, -1, -1):\n",
    "#             s_value = self.calculate_s_value(len(genotype)-1-i,right_list[::-1],genotype[i])\n",
    "\n",
    "#             right = {} \n",
    "# #             scale = 0 \n",
    "#             for state in self.get_diplotypes():\n",
    "#                 right[state] = 0\n",
    "#                 for next_state in self.get_diplotypes():\n",
    "#                     right[state] += right_list[0][next_state] * self.transition_prob(state, next_state) * self.emit_prob(next_state, genotype[i])\n",
    "# #                     scale += right[state]\n",
    "# #             for state in self.get_diplotypes():\n",
    "# #                 right[state] /= (scale_list[i+1]-scale_list[i])\n",
    "# #             scale_list.insert(0,scale)\n",
    "#             right_list.insert(0,right)\n",
    "        \n",
    "#         # rescale left\n",
    "# #         print('RIGHT')\n",
    "# #         print(right_list)\n",
    "# #         print(scale_list)\n",
    "# #         scaled_right_list = right_list.copy()\n",
    "# #         for i in range(len(right_list)-1,-1,-1):\n",
    "# #             for state in self.get_diplotypes():\n",
    "# #                 right_list[i][state] *= np.sum(scale_list[i:])\n",
    "        \n",
    "#         posterior = 0\n",
    "#         for state in self.get_diplotypes():\n",
    "#             posterior += right_list[0][state] * self.init_prob(state) * self.emit_prob(state, genotype[0])\n",
    "\n",
    "#         return posterior, right_list\n",
    "#     def check_convergence(self,all_iters_total_likelihood,eps):\n",
    "#         if np.linalg.norm(np.array(all_iters_total_likelihood[-1]) - np.array(all_iters_total_likelihood[-2])) < eps:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "#     def fit(self, genotypes, max_it,eps=1e-10):\n",
    "#         pseudocount = self.pseudocount\n",
    "#         # Train by Baum-Weltch\n",
    "#         # Inititalization\n",
    "#         all_iters_KL_divergence = []\n",
    "#         transitions,emissions,initial = self.initialize_HMM_parameters_randomly(self.genotypes, self.diplotypes, self.seed)\n",
    "#         for it in range(max_it):\n",
    "#             print(f'------------------Iter:{it}------------------')\n",
    "#              # Expectation\n",
    "#             sum_Px = 0\n",
    "#             # get the sum over Px first\n",
    "#             for j in range(len(genotypes)):\n",
    "#                 genotype = genotypes[j]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, _ = self.forward(genotype)\n",
    "#     #             r_Px, r_matrix = self.backward(genotype)\n",
    "#                 sum_Px += 1/f_Px\n",
    "# #             if it >= 1 and self.check_convergence(all_iters_total_likelihood,eps):\n",
    "# #                 print(all_iters_total_likelihood)\n",
    "# #                 break\n",
    "#             for m in range(len(genotypes)):\n",
    "#                 genotype = genotypes[m]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, f_matrix = self.forward(genotype)\n",
    "#                 r_Px, r_matrix = self.backward(genotype)\n",
    "#                 for k in self.get_diplotypes():\n",
    "#                     # Update transition matrix A\n",
    "#                     for l in self.get_diplotypes():\n",
    "#                         A = 0\n",
    "#                         for i in range(len(genotype)-1):\n",
    "#                             A += f_matrix[i][k] * self.transition_prob(k,l) *  self.emit_prob(l, genotype[i+1]) * r_matrix[i+1][l]\n",
    "#                         transitions[k][l] = pseudocount + sum_Px * A\n",
    "\n",
    "#                     # Update emission matrix E\n",
    "#                     for j, sigma in enumerate(self.get_genotypes()):\n",
    "#                         E = 0\n",
    "#                         for i in range(len(genotype)):\n",
    "#                             if genotype[i] == sigma:\n",
    "#                                 E += f_matrix[i][k] * r_matrix[i][k]\n",
    "\n",
    "#                         emissions[k][sigma] = pseudocount + sum_Px * E\n",
    "\n",
    "#                     # Update initial state matrix B\n",
    "#                     initial[k] = sum_Px * f_matrix[0][k] * r_matrix[0][k] \n",
    "#              # Maximization\n",
    "#             for k in self.get_diplotypes():\n",
    "#                 sum_A = 0\n",
    "#                 for l in self.get_diplotypes():\n",
    "#                     sum_A += transitions[k][l]\n",
    "#                 for l in self.get_diplotypes():\n",
    "#                     transitions[k][l] = transitions[k][l]/sum_A\n",
    "\n",
    "\n",
    "#                 sum_E = 0\n",
    "#                 for j, sigma in enumerate(self.get_genotypes()):\n",
    "#                     sum_E += emissions[k][sigma]\n",
    "#                 for j, sigma in enumerate(self.get_genotypes()):\n",
    "#                     emissions[k][sigma] = emissions[k][sigma]/sum_E\n",
    "# #             print('Param')\n",
    "# #             print(transitions[k])\n",
    "# #             print(emissions[k])\n",
    "#             sum_B = 0\n",
    "#             for k in self.get_diplotypes():\n",
    "#                 sum_B += initial[k]\n",
    "#             for k in self.get_diplotypes():\n",
    "#                 initial[k] = initial[k]/sum_B\n",
    "# #             # Maximization\n",
    "            \n",
    "# #             for k in self.get_diplotypes():\n",
    "# #                 all_a = []\n",
    "# #                 for l in self.get_diplotypes():\n",
    "# #                     all_a.append(transitions[k][l])\n",
    "# #                 all_normalized_a = self.sum_normalize(all_a)\n",
    "# #                 for l_index,l in enumerate(self.get_diplotypes()):\n",
    "# #                     transitions[k][l] = all_normalized_a[l_index]\n",
    "                \n",
    "# #                 all_e = []\n",
    "# #                 for j, sigma in enumerate(self.get_genotypes()):\n",
    "# #                     all_e.append(emissions[k][sigma])\n",
    "                \n",
    "# #                 all_normalized_e = self.sum_normalize(all_e)\n",
    "# #                 for sigma_index, sigma in enumerate(self.get_genotypes()):\n",
    "# #                     emissions[k][sigma] = all_normalized_e[sigma_index]\n",
    "\n",
    "# #             all_b = []\n",
    "# #             for k in self.get_diplotypes():\n",
    "# #                 all_b.append(initial[k])\n",
    "# #             all_normalized_b = self.sum_normalize(all_b)\n",
    "            \n",
    "# #             for k_index,k in enumerate(self.get_diplotypes()):\n",
    "# #                 initial[k] = all_normalized_b[k_index]\n",
    "# #             if it >= 1 and self.check_convergence(transitions,eps):\n",
    "# #                 print(all_iters_total_likelihood)\n",
    "# #                 break\n",
    "#             self.transitions = transitions\n",
    "#             self.emissions = emissions\n",
    "#             self.initial = initial\n",
    "#     def predict(self, genotype):\n",
    "#         # Predict by Viterbi\n",
    "#         previous_col_probs = {} \n",
    "#         traceback = []\n",
    "#         for state in self.get_diplotypes():\n",
    "#             previous_col_probs[state] = np.log(self.init_prob(state)) + np.log(self.emit_prob(state, genotype[0]))\n",
    "\n",
    "#         for t in range(1, len(genotype)): \n",
    "#             previous_col_probs_next = {}\n",
    "#             traceback_next = {}\n",
    "\n",
    "#             for next_state in self.get_diplotypes():  \n",
    "#                 k = {}\n",
    "#                 for this_state in self.get_diplotypes():\n",
    "#                     k[this_state] = previous_col_probs[this_state] + np.log(self.transition_prob(this_state, next_state)) \n",
    "#                 max_k = -np.inf\n",
    "#                 argmax_k = None\n",
    "#                 for state,val in k.items():\n",
    "#                     if val > max_k:\n",
    "#                         argmax_k = state\n",
    "#                         max_k = val\n",
    "#                 previous_col_probs_next[next_state] =  np.log(self.emit_prob(next_state, genotype[t])) + k[argmax_k]\n",
    "#                 traceback_next[next_state] = argmax_k\n",
    "\n",
    "#             previous_col_probs = previous_col_probs_next\n",
    "#             traceback.append(traceback_next)\n",
    "\n",
    "#         max_final_state = None\n",
    "#         max_final_prob = -np.inf\n",
    "#         for state,prob in previous_col_probs.items():\n",
    "#             if prob > max_final_prob:\n",
    "#                 max_final_prob = prob\n",
    "#                 max_final_state = state\n",
    "\n",
    "#         result = [max_final_state]\n",
    "#         for t in range(len(genotype)-2,-1,-1):\n",
    "#             result.append(traceback[t][max_final_state])\n",
    "#             max_final_state = traceback[t][max_final_state]\n",
    "\n",
    "#         return result[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5f732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "847fa2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class haplotypeHMM_fast(object):\n",
    "#     '''\n",
    "#     hidden_states -> mosaic state (X,Y), indicating states of diploids from haplotypes X and Y\n",
    "#     transition -> transition prob for mosaic state\n",
    "#     emission -> prob of genotype condition on mosaic state\n",
    "#     inital -> prob initial mosaic state\n",
    "    \n",
    "#     '''\n",
    "#     def __init__(self, alphabet, hidden_states, possible_haplotypes, seed=None):\n",
    "#         self._alphabet = alphabet\n",
    "#         self._hidden_states = hidden_states\n",
    "#         self._haplotypes = possible_haplotypes\n",
    "#         self._seed = seed\n",
    "#         self._initialize_theta()\n",
    "#         self._transitions, self._emissions, self._initial = self._initialize_HMM(self._seed)\n",
    "# #         if(self._transitions == None):\n",
    "# #             self._initialize_random(self._alphabet, self._hidden_states, self._seed)\n",
    "    \n",
    "#     def _emit(self, cur_state, symbol):\n",
    "#         return self._emissions[cur_state][symbol]\n",
    "    \n",
    "#     def _transition(self, cur_state, next_state):\n",
    "#         return self._transitions[cur_state][next_state]\n",
    "    \n",
    "#     def _init(self, cur_state):\n",
    "#         return self._initial[cur_state]\n",
    "\n",
    "#     def _states(self):\n",
    "#         for k in self._hidden_states:\n",
    "#             yield k\n",
    "#     def _emissions_by_theta(self,theta,state,prev_state):\n",
    "#         H = len(self._haplotypes)\n",
    "#         state_X,state_Y = state\n",
    "#         prev_state_X,prev_state_Y = prev_state\n",
    "#         if (state_X != prev_state_X) and (state_Y != prev_state_Y):\n",
    "#             return theta**2/H**2\n",
    "#         elif (state_X != prev_state_X) or (state_Y != prev_state_Y):\n",
    "#             return (1-theta) * theta/H + theta**2/(H**2)\n",
    "#         else:\n",
    "#             return (1-theta) ** 2+ 2*(1-theta)*theta/H + theta**2/(H**2)\n",
    "#     def _initialize_theta(self,):\n",
    "#         self._theta = np.ones(len(self._hidden_states))//100\n",
    "#     def _initialize_HMM(self,seed):\n",
    "#         transitions = {}\n",
    "#         emissions = {}\n",
    "#         initial = {}\n",
    "#         # initailize the inital prob by dirichlet distribution\n",
    "#         np.random.seed(seed=seed)\n",
    "#         initial_rand = np.random.dirichlet(np.ones(len(self._hidden_states)))\n",
    "#         for i, state in enumerate(self._states()):\n",
    "#             emissions[state] = {}\n",
    "#             transitions[state] = {}\n",
    "#             initial[state] = initial_rand\n",
    "#             E_rand = np.random.dirichlet(np.ones(len(self._alphabet)))\n",
    "#             for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                 emissions[state][sigma] = E_rand[j]\n",
    "#             for j, next_state in enumerate(self._states()):\n",
    "#                 transitions[state][next_state] = self._emissions_by_theta(self._theta[j],next_state,state)\n",
    "#         return transitions,emissions,initial\n",
    "# #     def _initialize_random(self, alphabet, states, seed):\n",
    "# #         alphabet = list(set(alphabet))\n",
    "# #         alphabet.sort()\n",
    "# #         states = list(set(states))\n",
    "# #         states.sort()\n",
    "# #         self._alphabet = alphabet\n",
    "# #         self._hidden_states = states\n",
    "\n",
    "# #         #Initialize empty matrices A and E with pseudocounts\n",
    "# #         A = {}\n",
    "# #         E = {}\n",
    "# #         I = {}\n",
    "# #         np.random.seed(seed=seed)\n",
    "# #         I_rand = np.random.dirichlet(np.ones(len(self._hidden_states)))\n",
    "# #         for i, state in enumerate(self._states()):\n",
    "# #             E[state] = {}\n",
    "# #             A[state] = {}\n",
    "# #             I[state] = I_rand[i]\n",
    "# #             E_rand = np.random.dirichlet(np.ones(len(self._alphabet)))\n",
    "# #             A_rand = np.random.dirichlet(np.ones(len(self._hidden_states)))\n",
    "# #             for j, sigma in enumerate(self._get_alphabet()):\n",
    "# #                 E[state][sigma] = E_rand[j]\n",
    "# #             for j, next_state in enumerate(self._states()):\n",
    "# #                 A[state][next_state] = A_rand[j]\n",
    "                \n",
    "# #         self._transitions = A\n",
    "# #         self._emissions = E\n",
    "# #         self._initial = I\n",
    "# #         return\n",
    "        \n",
    "#     def _get_alphabet(self):\n",
    "#         for sigma in self._alphabet:\n",
    "#             yield sigma\n",
    "\n",
    "#     def _Ca(self,hap_a,previous_left_chain,previous_geno):\n",
    "#         Ca = 0\n",
    "#         for hap_b in self._haplotypes:\n",
    "#             state = (hap_a,hap_b)\n",
    "#             Ca += previous_left_chain[state] * self._emit(state,previous_geno)\n",
    "#         return Ca\n",
    "#     def _C(self,previous_left_chain,previous_geno):\n",
    "#         C = 0\n",
    "#         for hap_a in self._haplotypes:\n",
    "#             C += self._Ca(hap_a,previous_left_chain,previous_geno)\n",
    "#         return C\n",
    "#     def forward(self, sequence):\n",
    "#         H = len(self._haplotypes)\n",
    "#         # calculate left chain prob\n",
    "#         left_list = [] \n",
    "#         left = {}\n",
    "#         for state in self._states():\n",
    "#             left[state] = 1\n",
    "#         left_list.append(left)\n",
    "\n",
    "#         for j in range(1, len(sequence)):  # For each position in the sequence\n",
    "#             left = {}\n",
    "#             for state in self._states(): # For each state\n",
    "#                 (x,y) = state\n",
    "#                 # refer to MACH paper\n",
    "#                 left[state] = left_list[j-1][state] * self._emit(state,sequence[j-1]) * (1-self._theta[j]) ** 2 + \\\n",
    "#                 self._Ca(x,left_list[j-1],sequence[j-1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._Ca(y,left_list[j-1],sequence[j-1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._C(left_list[j-1],sequence[j-1]) * self._theta[j]**2 / H**2\n",
    "\n",
    "#             left_list.append(left)\n",
    "#         Px = 0\n",
    "#         for state in self._states():\n",
    "#             Px += left_list[-1][state]\n",
    "\n",
    "#         return Px, left_list\n",
    "#     def backward(self, sequence):\n",
    "#         H = len(self._haplotypes)\n",
    "#         # calculate right chain prob\n",
    "#         right_list = [] \n",
    "#         right = {}\n",
    "#         for state in self._states():\n",
    "#             right[state] = 1\n",
    "#         right_list.append(right)\n",
    "\n",
    "#         for j in range(len(sequence)-2,-1,-1):  # For each position in the sequence\n",
    "#             right = {}\n",
    "#             for state in self._states(): # For each state\n",
    "#                 (x,y) = state\n",
    "#                 # refer to MACH paper\n",
    "#                 right[state] = right_list[0][state] * self._emit(state,sequence[j+1]) * (1-self._theta[j]) ** 2 + \\\n",
    "#                 self._Ca(x,right_list[0],sequence[j+1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._Ca(y,right_list[0],sequence[j+1]) * (1-self._theta[j]) * self._theta[j] / H + \\\n",
    "#                 self._C(right_list[0],sequence[j+1]) * self._theta[j]**2 / H**2\n",
    "\n",
    "#             right_list.insert(0,right)\n",
    "#         Px = 0\n",
    "#         for state in self._states():\n",
    "#             Px += right_list[0][state] * self._init(state) * self._emit(state, sequence[0])\n",
    "\n",
    "#         return Px, right_list\n",
    "    \n",
    "#     def baum_welch(self, sequences, pseudocount=1e-100):\n",
    "#         \"\"\" The baum-welch algorithm for unsupervised HMM parameter learning\n",
    "\n",
    "#         Args:\n",
    "#             sequence (list): a list of sequences containing valid emissions from the HMM\n",
    "#             pseudocount (float): small pseudocount value (default: 1e-100)\n",
    "\n",
    "#         Returns:\n",
    "#             None but updates the current HMM model parameters:\n",
    "#              self._transitions, self._emissions, self._initial\n",
    "        \n",
    "#         \"\"\"   \n",
    "#         # Inititalization\n",
    "#         transition,emissions,initial = self._initialize_HMM(self._seed)\n",
    "\n",
    "#         # set the max iteration to 1 here to print the first iteration\n",
    "#         max_it = 1\n",
    "#         for it in range(max_it):\n",
    "#              # Expectation\n",
    "#             sum_Px = 0\n",
    "#             # get the sum over Px first\n",
    "#             for j in range(len(sequences)):\n",
    "#                 sequence = sequences[j]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, _ = self.forward(sequence)\n",
    "#     #             r_Px, r_matrix = self.backward(sequence)\n",
    "#                 sum_Px += 1/f_Px\n",
    "#             for j in range(len(sequences)):\n",
    "#                 sequence = sequences[j]\n",
    "#                 # forward and backward\n",
    "#                 f_Px, f_matrix = self.forward(sequence)\n",
    "#                 r_Px, r_matrix = self.backward(sequence)\n",
    "#                 for k in self._states():\n",
    "#                     # Update transition matrix A\n",
    "#                     for l in self._states():\n",
    "#                         A = 0\n",
    "#                         for i in range(len(sequence)-1):\n",
    "#                             A += f_matrix[i][k] * self._transition(k,l) *  self._emit(l, sequence[i+1]) * r_matrix[i+1][l]\n",
    "#                         transition[k][l] = sum_Px * A\n",
    "\n",
    "#                     # Update emission matrix E\n",
    "#                     for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                         E = 0\n",
    "#                         for i in range(len(sequence)):\n",
    "#                             if sequence[i] == sigma:\n",
    "#                                 E += f_matrix[i][k] * r_matrix[i][k]\n",
    "\n",
    "#                         emissions[k][sigma] = sum_Px * E\n",
    "\n",
    "#                     # Update initial state matrix B\n",
    "#                     initial[k] = sum_Px * f_matrix[0][k] * r_matrix[0][k]\n",
    "\n",
    "#             # Maximization\n",
    "#             for k in self._states():\n",
    "#                 sum_A = 0 \n",
    "#                 for l in self._states():\n",
    "#                     sum_A += transition[k][l]\n",
    "#                 for l in self._states():\n",
    "#                     transition[k][l] = transition[k][l]/sum_A\n",
    "\n",
    "\n",
    "#                 sum_E = 0\n",
    "#                 for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                     sum_E += emissions[k][sigma]\n",
    "#                 for j, sigma in enumerate(self._get_alphabet()):\n",
    "#                     emissions[k][sigma] = emissions[k][sigma]/sum_E\n",
    "\n",
    "#             sum_B = 0\n",
    "#             for k in self._states():\n",
    "#                 sum_B += initial[k]\n",
    "#             for k in self._states():\n",
    "#                 initial[k] = initial[k]/sum_B\n",
    "\n",
    "#     #         self.__init__(self._get_alphabet, self._states, A=None, E=None, B=None, seed=None):\n",
    "#             self._transitions = transition\n",
    "#             self._emissions = emissions\n",
    "#             self._initial = initial\n",
    "# #             print(self)\n",
    "#         pass\n",
    "#     def viterbi(self, sequence):\n",
    "#         \"\"\" The viterbi algorithm for decoding a string using a HMM\n",
    "\n",
    "#         Args:\n",
    "#             sequence (list): a list of valid emissions from the HMM\n",
    "\n",
    "#         Returns:\n",
    "#             result (list): optimal path through HMM given the model parameters\n",
    "#                            using the Viterbi algorithm\n",
    "        \n",
    "#         Pseudocode for Viterbi:\n",
    "#             Initialization (ð‘–=0): ð‘£ð‘˜(ð‘–)=ð‘’ð‘˜(ðœŽ)ð‘ð‘˜.\n",
    "#             Recursion (ð‘–=1â€¦ð‘‡): ð‘£ð‘™(ð‘–)=ð‘’ð‘™(ð‘¥ð‘–) maxð‘˜(ð‘£ð‘˜(ð‘–âˆ’1)ð‘Žð‘˜ð‘™); \n",
    "#                                 ptrð‘–(ð‘™)= argmaxð‘˜(ð‘£ð‘˜(ð‘–âˆ’1)ð‘Žð‘˜ð‘™).\n",
    "#             Termination: ð‘ƒ(ð‘¥,ðœ‹âˆ—)= maxð‘˜(ð‘£ð‘˜(ð‘™)ð‘Žð‘˜0); \n",
    "#                              ðœ‹âˆ—ð‘™= argmaxð‘˜(ð‘£ð‘˜(ð‘™)ð‘Žð‘˜0).\n",
    "#             Traceback: (ð‘–=ð‘‡â€¦1): ðœ‹âˆ—ð‘–âˆ’1= ptrð‘–(ðœ‹âˆ—ð‘–).\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Initialization (ð‘–=0): ð‘£ð‘˜(ð‘–)=ð‘’ð‘˜(ðœŽ)ð‘ð‘˜.\n",
    "#         # Initialize trellis and traceback matrices\n",
    "#         # trellis will hold the vi data as defined by Durbin et al.\n",
    "#         # and trackback will hold back pointers\n",
    "#         trellis = {} # This only needs to keep the previous column probabilities\n",
    "#         traceback = [] # This will need to hold all of the traceback data so will be an array of dicts()\n",
    "#         for state in self._states():\n",
    "#             trellis[state] = np.log10(self._init(state)) + np.log10(self._emit(state, sequence[0])) # b * e(0) for all k\n",
    "            \n",
    "#         # Next we do the recursion step:\n",
    "#         # Recursion (ð‘–=1â€¦ð‘‡): ð‘£ð‘™(ð‘–)=ð‘’ð‘™(ð‘¥ð‘–) maxð‘˜(ð‘£ð‘˜(ð‘–âˆ’1)ð‘Žð‘˜ð‘™); \n",
    "#         #                 ptrð‘–(ð‘™)= argmaxð‘˜(ð‘£ð‘˜(ð‘–âˆ’1)ð‘Žð‘˜ð‘™).\n",
    "#         for t in range(1, len(sequence)):  # For each position in the sequence\n",
    "#             trellis_next = {}\n",
    "#             traceback_next = {}\n",
    "\n",
    "#             for next_state in self._states():    # Calculate maxk and argmaxk\n",
    "#                 k={}\n",
    "#                 for cur_state in self._states():\n",
    "#                     k[cur_state] = trellis[cur_state] + np.log10(self._transition(cur_state, next_state)) # k(t-1) * a\n",
    "#                 argmaxk = max(k, key=k.get)\n",
    "#                 trellis_next[next_state] =  np.log10(self._emit(next_state, sequence[t])) + k[argmaxk] # k * e(t)\n",
    "#                 traceback_next[next_state] = argmaxk\n",
    "                \n",
    "#             #Overwrite trellis \n",
    "#             trellis = trellis_next\n",
    "#             #Keep trackback pointer matrix\n",
    "#             traceback.append(traceback_next)\n",
    "            \n",
    "#         # Termination: ð‘ƒ(ð‘¥,ðœ‹âˆ—)= maxð‘˜(ð‘£ð‘˜(ð‘™)ð‘Žð‘˜0); \n",
    "#         #                  ðœ‹âˆ—ð‘™= argmaxð‘˜(ð‘£ð‘˜(ð‘™)ð‘Žð‘˜0).\n",
    "#         max_final_state = max(trellis, key=trellis.get)\n",
    "#         max_final_prob = trellis[max_final_state]\n",
    "                \n",
    "#         # Traceback: (ð‘–=ð‘‡â€¦1): ðœ‹âˆ—ð‘–âˆ’1= ptrð‘–(ðœ‹âˆ—ð‘–).\n",
    "#         result = [max_final_state]\n",
    "#         for t in reversed(range(len(sequence)-1)):\n",
    "#             result.append(traceback[t][max_final_state])\n",
    "#             max_final_state = traceback[t][max_final_state]\n",
    "\n",
    "#         return result[::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6434dddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2993a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "hidden_states =  list(all_possible_dips)\n",
    "alphabet = [0,1,2] # DNA Alphabet\n",
    "\n",
    "model = haplotypeHMM(alphabet, hidden_states,range(len(all_possible_haps_index)),seed=70,pseudocount=1e-100)\n",
    "\n",
    "model.fit(genos[:5,:10].T,10,eps=1e-6)\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c9f7bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [2, 0, 1, 0, 1, 1, 2, 1, 1, 2],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [2, 0, 1, 0, 1, 1, 2, 1, 1, 2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genos[:5,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acae3070",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (37,) (37,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbaum_welch_scaling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenos\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 28\u001b[0m, in \u001b[0;36mbaum_welch_scaling\u001b[0;34m(O, N, M, T, epsilon, max_iter)\u001b[0m\n\u001b[1;32m     23\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# E step\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Compute alpha using recursion\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mpi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     29\u001b[0m     alpha[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m pi \u001b[38;5;241m*\u001b[39m B[:, O[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m/\u001b[39m c[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T):\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (37,) (37,5) "
     ]
    }
   ],
   "source": [
    "baum_welch_scaling(genos[:5,:10].T,len(hidden_states),len(alphabet),len(genos[:5,:10].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011f862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
