{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e63a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from haplotypeSegmentGraph import haplotypeSegmentGraph\n",
    "from haplotypeHMM import haplotypeHMM\n",
    "from calculateSwitchErrorRate import calculate_switch_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e3c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_f_path = 'examples/CCDG_14151_B01_GRM_WGS_2020-08-05_chr19.filtered.shapeit2-duohmm-phased.2504.43-47Mb.ALL.maf01.haps.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e246cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_numSNPs = 26246\n",
    "total_numSamples = 2504\n",
    "B = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "64e7f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_seeds = []\n",
    "row_seeds = []\n",
    "for examined_numSNPs in [5,10,20,50,100,200]:\n",
    "    col_seeds.append(random.randint(0,1000))\n",
    "for num_samples in [100,300,600,1200,2504]:\n",
    "    row_seeds.append(random.randint(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5659c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_seeds = [877, 927, 437, 264, 910, 656, 425, 252, 864, 150, 289, 952, 756, 485, 852, 471, 927, 956, 397, 815, 112, 387, 722, 732, 113, 57, 207, 925, 720, 861, 869, 751, 112, 211, 760]\n",
    "# row_seeds = [994, 302, 123, 843, 740, 285, 250, 150, 431, 495, 148, 478, 524, 434, 534, 827, 184, 788, 10, 196, 460, 311, 340, 607, 762, 725, 794, 988, 589, 471, 92, 335, 410, 460, 601]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ae8203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "40cf142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b07f63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(hap_f_path,header=None,sep=' ')\n",
    "# make sure sort by position\n",
    "df = df.sort_values(by=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "results_dict = {}\n",
    "genos_dict = {}\n",
    "labels_dict = {}\n",
    "for B in [2,3,4,5,6]:\n",
    "    time_dict[B] = {}\n",
    "    results_dict[B] = {}\n",
    "    genos_dict[B] = {}\n",
    "    labels_dict[B] = {}\n",
    "    # SER_dict = {}\n",
    "    for snp_index,examined_numSNPs in enumerate([5,10,20,50,100,200]):\n",
    "        if examined_numSNPs in [5,10]:\n",
    "            threads = 6\n",
    "        else:\n",
    "            threads = 20\n",
    "        time_dict[B][examined_numSNPs] = {}\n",
    "        results_dict[B][examined_numSNPs] = {}\n",
    "        genos_dict[B][examined_numSNPs] = {}\n",
    "        labels_dict[B][examined_numSNPs] = {}\n",
    "        for sample_index,num_samples in enumerate([100,300,600,1200,2504]):\n",
    "            # set random seed\n",
    "            np.random.seed(row_seeds[sample_index])\n",
    "            snps_masking = np.random.choice(range(df.shape[0]), examined_numSNPs)\n",
    "            snps_df = df.loc[snps_masking]\n",
    "            snps_df = snps_df.sort_values(by=2)\n",
    "            # prepare input data\n",
    "            genetic_pos = snps_df[2]\n",
    "            haps = snps_df.loc[:,5:].values\n",
    "            labels = []\n",
    "            for i in range(haps.shape[1]//2):\n",
    "                labels.append((haps[:,i],haps[:,haps.shape[1]//2+i]))\n",
    "            labels = np.array(labels)\n",
    "            genos = np.full(shape=(haps.shape[0],haps.shape[1]//2),fill_value=-1,dtype=int)\n",
    "            ## create genotypes by combining each pair of haplotypes\n",
    "            for i in range(genos.shape[1]):\n",
    "                genos[:,i] = haps[:,2*i] + haps[:,2*i+1]\n",
    "            genos = genos.T\n",
    "            # set the seed for col\n",
    "            np.random.seed(col_seeds[snp_index])\n",
    "            sample_masking = np.random.choice(range(genos.shape[0]), num_samples)\n",
    "            genos = genos[sample_masking,:]\n",
    "            labels = labels[sample_masking,:,:]\n",
    "            # run the HMM\n",
    "            st = time.time()\n",
    "            hap_graph = haplotypeSegmentGraph(genos,genetic_pos,B)\n",
    "            hmm = haplotypeHMM(hap_graph)\n",
    "            results = hmm.predict(genos,threads=threads)\n",
    "            duration = time.time()  - st\n",
    "            # evaluation\n",
    "    #         all_SER = calculate_switch_error_rate(results,labels)\n",
    "    #         SER_dict[examined_numSNPs][num_samples]  = all_SER\n",
    "            time_dict[B][examined_numSNPs][num_samples]  = duration * threads\n",
    "            results_dict[B][examined_numSNPs][num_samples] = results\n",
    "            genos_dict[B][examined_numSNPs][num_samples] = genos\n",
    "            labels_dict[B][examined_numSNPs][num_samples] = labels\n",
    "    with open(f'results_B_{B}','wb') as f:\n",
    "        pickle.dump([time_dict,results_dict,genos_dict,labels_dict],f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55928f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0787b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results.pkl','wb') as f:\n",
    "#     pickle.dump([time_dict,results_dict,genos_dict,labels_dict],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "79dc5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_switch_error(prediction,truth):\n",
    "    SERs = []\n",
    "#     hetero_masking = truth[0] + truth[1] == 1\n",
    "    hetero_masking = truth[0] + truth[1] != -1\n",
    "    hetero_prediction = prediction[0][hetero_masking]\n",
    "    hetero_truth = truth[0][hetero_masking]\n",
    "    if hetero_truth.shape[0] == 0:\n",
    "        return 0\n",
    "    hap_type = hetero_prediction == hetero_truth\n",
    "    num_switch = 0\n",
    "    for i in range(len(hap_type)-1):\n",
    "        if hap_type[i] != hap_type[i+1]:\n",
    "            num_switch += 1\n",
    "    SERs.append(num_switch/hap_type.shape[0])\n",
    "    \n",
    "    hetero_prediction = prediction[1][hetero_masking]\n",
    "    hetero_truth = truth[0][hetero_masking]\n",
    "    if hetero_truth.shape[0] == 0:\n",
    "        return 0\n",
    "    hap_type = hetero_prediction == hetero_truth\n",
    "    num_switch = 0\n",
    "    for i in range(len(hap_type)-1):\n",
    "        if hap_type[i] != hap_type[i+1]:\n",
    "            num_switch += 1\n",
    "    SERs.append(num_switch/hap_type.shape[0])\n",
    "    \n",
    "    return np.min(SERs)\n",
    "def calculate_switch_error_rate(results,labels):\n",
    "    all_SER = []\n",
    "    for i in range(len(results)):\n",
    "        SER = get_switch_error(results[i],labels[i])\n",
    "        all_SER.append(SER)\n",
    "    return all_SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2d26e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b9814823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculcate_hamming_dist(results,labels):\n",
    "    all_error = []\n",
    "    for i in range(len(results)):\n",
    "        h1 = hamming(results[i][0],labels[i][0]) + hamming(results[i][1],labels[i][1])\n",
    "        h2 = hamming(results[i][0],labels[i][1]) + hamming(results[i][1],labels[i][0])\n",
    "        all_error.append(np.min([h1,h2]))\n",
    "    return all_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98040279",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "num_SNPs = 200\n",
    "for sample_size in results_dict[num_SNPs]:\n",
    "    x.append(sample_size)\n",
    "    y.append(np.mean(calculate_switch_error_rate(results_dict[num_SNPs][sample_size],labels_dict[num_SNPs][sample_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ee9a7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "sample_size = 2504\n",
    "for examined_numSNPs in [5,10,20,50,100,200]:\n",
    "#     for sample_size in results_dict[examined_numSNPs]:\n",
    "    x.append(examined_numSNPs)\n",
    "    y.append(np.mean(calculate_switch_error_rate(results_dict[examined_numSNPs][sample_size],labels_dict[examined_numSNPs][sample_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0ff633ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2930511182108626,\n",
       " 0.3047923322683706,\n",
       " 0.2319888178913738,\n",
       " 0.23825079872204474,\n",
       " 0.26673322683706074,\n",
       " 0.29781349840255594]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "33fbba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "sample_size = 2504\n",
    "for examined_numSNPs in [5,10,20,50,100,200]:\n",
    "#     for sample_size in results_dict[examined_numSNPs]:\n",
    "    x.append(examined_numSNPs)\n",
    "    y.append(np.mean(calculcate_hamming_dist(results_dict[examined_numSNPs][sample_size],labels_dict[examined_numSNPs][sample_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "14f445e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "54ee888e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.34"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1263df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "# for examined_numSNPs in [5,10,20,50,100,200]:\n",
    "#     for num_samples in [100,300,600,1200,2504]:\n",
    "#         hap_graph = haplotypeSegmentGraph(genos_dict[examined_numSNPs][num_samples],genetic_pos,B)\n",
    "#         SER = np.mean(calculate_switch_error_rate(results_dict[examined_numSNPs][num_samples],labels_dict[examined_numSNPs][num_samples]))\n",
    "#         state = sum([len(nodes) for nodes in hap_graph.nodes.values()]) / len(hap_graph.nodes)\n",
    "#         x.append(state)\n",
    "#         y.append(SER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354a25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haplotypeHMM [/nfs/turbo/umms-kinfai/haorli/envs/haplotypeHMM]",
   "language": "python",
   "name": "conda_haplotypehmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
